<!doctype html>
<html data-n-head-ssr lang="zh" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22zh%22%7D%7D">
  <head >
    <title>大模型分布式训练并行技术（五）-序列并行近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上 - 掘金</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width, initial-scale=1, user-scalable=no, viewport-fit=cover"><meta data-n-head="ssr" name="apple-itunes-app" content="app-id=987739104"><meta data-n-head="ssr" name="theme-color" content="#ffffff"><meta data-n-head="ssr" name="msapplication-TileColor" content="#da532c"><meta data-n-head="ssr" vmid="description" name="description" content="近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡"><meta data-n-head="ssr" vmid="keywords" name="keywords" content="LLM"><link data-n-head="ssr" rel="preconnect" href="//unpkg.byted-static.com/" crossorigin="anonymous"><link data-n-head="ssr" rel="preconnect" href="//lf3-cdn-tos.bytescm.com" crossorigin="anonymous"><link data-n-head="ssr" rel="preconnect" href="//mcs.snssdk.com" crossorigin="anonymous"><link data-n-head="ssr" rel="preconnect" href="//i.snssdk.com" crossorigin="anonymous"><link data-n-head="ssr" rel="dns-prefetch" href="//lf3-short.ibytedapm.com"><link data-n-head="ssr" rel="dns-prefetch" href="//lf3-cdn-tos.bytescm.com"><link data-n-head="ssr" rel="dns-prefetch" href="//api.juejin.cn"><link data-n-head="ssr" rel="dns-prefetch" href="//lf-cdn-tos.bytescm.com"><link data-n-head="ssr" rel="dns-prefetch" href="//unpkg.byted-static.com"><link data-n-head="ssr" rel="dns-prefetch" href="//p1-juejin.byteimg.com"><link data-n-head="ssr" rel="dns-prefetch" href="//p3-juejin.byteimg.com"><link data-n-head="ssr" rel="dns-prefetch" href="//p6-juejin.byteimg.com"><link data-n-head="ssr" rel="dns-prefetch" href="//p9-juejin.byteimg.com"><link data-n-head="ssr" rel="dns-prefetch" href="//p1-jj.byteimg.com"><link data-n-head="ssr" rel="dns-prefetch" href="//p2-jj.byteimg.com"><link data-n-head="ssr" rel="dns-prefetch" href="//p6-jj.byteimg.com"><link data-n-head="ssr" rel="dns-prefetch" href="//p9-jj.byteimg.com"><link data-n-head="ssr" rel="dns-prefetch" href="//mcs.snssdk.com"><link data-n-head="ssr" rel="dns-prefetch" href="//i.snssdk.com"><link data-n-head="ssr" rel="apple-touch-icon" sizes="180x180" href="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/favicons/apple-touch-icon.png"><link data-n-head="ssr" rel="icon" type="image/png" sizes="32x32" href="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/favicons/favicon-32x32.png"><link data-n-head="ssr" rel="icon" type="image/png" sizes="16x16" href="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/favicons/favicon-16x16.png"><link data-n-head="ssr" rel="mask-icon" href="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/favicons/safari-pinned-tab.svg" color="#1E80FF"><link data-n-head="ssr" rel="manifest" href="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/favicons/site.webmanifest"><link data-n-head="ssr" rel="search" title="掘金" href="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/search.xml" type="application/opensearchdescription+xml"><link data-n-head="ssr" rel="stylesheet" href="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/bytedesign.min.css"><link data-n-head="ssr" rel="canonical" href="https://juejin.cn/post/7273680143658287156"><script data-n-head="ssr" type="text/javascript" data-sdk-glue-default="load" src="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/rc-client-security-web-glue/1.0.0.19/sdk-glue.js"></script><script data-n-head="ssr" type="text/javascript" data-sdk-glue-default="init">
        (function (){
          var options = {
            bdms: {
              aid: 2608,
              paths: [
                '/growth_api/v1/publish_benefit_history',
                '/growth_api/v1/check_in',
                '/growth_api/v1/lottery/draw',
                '/growth_api/v1/lottery/ten_draw',
                '/web_shorten',
                '/user_api/v1/user/get',
                '/interact_api/v1/digg/save',
                '/interact_api/v1/digg/query_page',
                '/interact_api/v1/comment/list',
                '/interact_api/v1/comment/hots',
                '/content_api/v1/article/detail',
                '/user_api/v1/follow/followees',
                '/user_api/v1/follow/followers',
                '/interact_api/v1/follow/tag_list',
                '/recommend_api/v1/article/recommend_cate_feed',
                '/interact_api/v1/comment/publish',
                '/interact_api/v1/reply/publish',
                '/growth_api/v1/get_benefit_page',
                '/growth_api/v1/get_cur_point',
                '/growth_api/v1/ten_draw', 
                '/growth_api/v1/draw',
                '/growth_api/v1/lottery_config/get',
              ]
            },
            verifyCenter: {
              interceptPathList: [
                '/user_api/v1/user/get',
                '/interact_api/v1/digg/save',
                '/interact_api/v1/digg/query_page',
                '/interact_api/v1/comment/list',
                '/interact_api/v1/comment/hots',
                '/content_api/v1/article/detail',
                '/user_api/v1/follow/followees',
                '/user_api/v1/follow/followers',
                '/interact_api/v1/follow/tag_list',
                '/recommend_api/v1/article/recommend_cate_feed',
              ],
              commonOptions: {
                aid: 2608,
                repoId: 56081
              },
              captchaOptions: {
                showMode: 'mask',
              },
            }
          }
        var sdkInfo = {
          bdms: {
            init: function (options) {
              window.bdms.init(options)
            },
            isLoaded: function () {
              return !!window.bdms
            },
            srcList: [
              'https://lf-headquarters-speed.yhgfb-cn-static.com/obj/rc-client-security/web/stable/1.0.0.33/bdms.js',
              'https://lf-c-flwb.bytetos.com/obj/rc-client-security/web/stable/1.0.0.33/bdms.js',
            ],
          },
          verifyCenter: {
            init: function (options) {
              window.TTGCaptcha.init(options);
            },
            isLoaded: function () {
              return !!window.TTGCaptcha;
            },
            srcList: [
              'https://lf-cdn-tos.bytescm.com/obj/rc-verifycenter/sec_sdk_build/4.0.10/captcha/index.js',
              'https://lf-rc1.yhgfb-cn-static.com/obj/rc-verifycenter/sec_sdk_build/4.0.10/captcha/index.js',
            ],
          }
        }
        window._SdkGlueInit(options, sdkInfo)
        })();
        </script><script data-n-head="ssr" vmid="slardar" type="text/javascript" crossorigin="anonymous">;(function (w, d, u, b, n, pc, ga, ae, po, s, p, e, t, pp) {pc = 'precollect';ga = 'getAttribute';ae = 'addEventListener';po = 'PerformanceObserver';s = function (m) {p = [].slice.call(arguments);p.push(Date.now(), location.href);(m == pc ? s.p.a : s.q).push(p)};s.q = [];s.p = { a: [] };w[n] = s;e = document.createElement('script');e.src = u + '?bid=' + b + '&globalName=' + n;e.crossOrigin = u.indexOf('sdk-web') > 0 ? 'anonymous' : 'use-credentials';d.getElementsByTagName('head')[0].appendChild(e);if (ae in w) {s.pcErr = function (e) {e = e || w.event;t = e.target || e.srcElement;if (t instanceof Element || t instanceof HTMLElement) {if (t[ga]('integrity')) {w[n](pc, 'sri', t[ga]('href') || t[ga]('src'))} else {w[n](pc, 'st', { tagName: t.tagName, url: t[ga]('href') || t[ga]('src') })}} else {w[n](pc, 'err', e.error || e.message)}};s.pcRej = function (e) {e = e || w.event;w[n](pc, 'err', e.reason || (e.detail && e.detail.reason))};w[ae]('error', s.pcErr, true);w[ae]('unhandledrejection', s.pcRej, true);};if('PerformanceLongTaskTiming' in w) {pp = s.pp = { entries: [] };pp.observer = new PerformanceObserver(function (l) {pp.entries = pp.entries.concat(l.getEntries())});pp.observer.observe({ entryTypes: ['longtask', 'largest-contentful-paint','layout-shift'] })}})(window,document,'https://lf3-short.ibytedapm.com/slardar/fe/sdk-web/browser.cn.js','2608','SlardarWeb')</script><script data-n-head="ssr" type="text/javascript" src="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/slardar-plugin/imageReport.js"></script><script data-n-head="ssr" type="text/javascript" src="https://lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/static/cdn-retry/bundle-dcf007.js" id="cdn-retry" defer></script><script data-n-head="ssr" type="application/ld+json">[{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://juejin.cn/post/7273680143658287156"},"headline":"大模型分布式训练并行技术（五）-序列并行","description":"近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡","image":["https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f5874bf342044e49a66d5f9a5e8d88bb~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=800&h=500&s=83748&e=webp&b=23443d"],"author":{"@type":"Organization","name":"吃果冻不吐果冻皮"},"publisher":{"@type":"Organization","name":"掘金","logo":{"@type":"ImageObject","url":"//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/e08da34488b114bd4c665ba2fa520a31.svg"}},"datePublished":"2023-09-01T14:30:08+00:00","dateModified":"2023-09-02T06:44:12+00:00"},{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","name":"稀土掘金","position":1,"item":"https://juejin.cn"},{"@type":"ListItem","name":"人工智能","position":2,"item":"https://juejin.cn/ai"},{"@type":"ListItem","name":"文章","position":3}]}]</script><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/105ea51.js" as="script"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/8acc73a.js" as="script"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/80ab6d9.js" as="script"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/app.2049241.css" as="style"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/90cf368.js" as="script"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/layouts/default.846c2b6.css" as="style"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/e4973f7.js" as="script"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/e1944c2.js" as="script"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/11.d5b5867.css" as="style"><link rel="preload" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/f33ff28.js" as="script"><link rel="stylesheet" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/app.2049241.css"><link rel="stylesheet" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/layouts/default.846c2b6.css"><link rel="stylesheet" href="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/11.d5b5867.css">
  </head>
  <body >
    <script data-n-head="ssr" type="text/javascript" data-pbody="true">(function () {
    const pages = [
        /^\/$/,
        /^\/following$/,
        /^\/recommended$/,
        '^/pins.*',
        '^/pin.*',
        /^\/course(?!\/payment\/)/,
        /^\/post\/.*/,
        '^/hot.*',
        /^\/book\/\d+/,
        /^\/video\/\d+/,
        /^\/user\/settings.*/,
        /^\/spost\/\d+/,
        /^\/notification(?!\/im)/,
        '^/backend',
        '^/frontend',
        '^/android',
        '^/ios',
        '^/ai',
        '^/freebie',
        '^/career',
        '^/article',
        '^/player',
    ];
    function isInJuejinApp() {
        const userAgent = typeof navigator !== 'undefined' ? navigator.userAgent : '';
        return /juejin/i.test(userAgent);
    }
    if (typeof window !== 'undefined' && !isInJuejinApp()) {
        try {
            const path = window.location.pathname;
            const isAvailable = pages.some((page) => {
                const reg = new RegExp(page);
                return reg.test(path);
            });
            if (isAvailable) {
                const localValue = localStorage.getItem('juejin_2608_theme') || '{}';
                let { theme = 'light', isFollowSystem = false } = JSON.parse(localValue);
                if (isFollowSystem) {
                    const themeMedia = window.matchMedia('(prefers-color-scheme: light)');
                    theme = themeMedia.matches ? 'light' : 'dark';
                    localStorage.setItem('juejin_2608_theme', JSON.stringify({ theme, isFollowSystem }));
                }
                document.body.setAttribute('data-theme', theme);
            }
            else {
                document.body.setAttribute('data-theme', 'light');
            }
        }
        catch (e) {
            console.error('浏览器不支持localStorage');
        }
    }
})()</script><div data-server-rendered="true" id="__nuxt"><div id="__layout"><div id="juejin"><div class="view-container" data-v-cd15ceae data-v-0140422c><div class="main-header-box" data-v-cd15ceae><header data-fetch-key="0" class="main-header main-header unauthorized visible" data-v-03bb4e82 data-v-cd15ceae><div class="container" data-v-03bb4e82><a href="/" class="logo" data-v-03bb4e82><img src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/e08da34488b114bd4c665ba2fa520a31.svg" alt="稀土掘金" class="logo-img" data-v-03bb4e82> <img src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/6c61ae65d1c41ae8221a670fa32d05aa.svg" alt="稀土掘金" class="mobile" data-v-03bb4e82></a> <!----> <nav role="navigation" class="main-nav" data-v-03bb4e82><ul class="nav-list" data-v-03bb4e82><!----> <li class="main-nav-list" data-v-03bb4e82><div class="phone-show-menu" data-v-03bb4e82><span data-v-03bb4e82>首页</span> <svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="unfold16-icon" data-v-03bb4e82 data-v-03bb4e82><path d="M2.45025 4.82431C2.17422 4.49957 2.40501 4.00049 2.83122 4.00049H9.16878C9.59498 4.00049 9.82578 4.49957 9.54975 4.82431L6.38097 8.55229C6.1813 8.78719 5.8187 8.78719 5.61903 8.55229L2.45025 4.82431Z" data-v-03bb4e82 data-v-03bb4e82></path></svg></div> <ul class="phone-hide" data-v-03bb4e82><li class="nav-item link-item" data-v-03bb4e82><a href="/" data-v-03bb4e82>首页</a></li> <li class="nav-item link-item bots" data-v-03bb4e82><a href="/bots" data-v-03bb4e82>
                BOT
                <span class="text" data-v-03bb4e82><!----></span></a></li> <li class="nav-item link-item activities" data-v-03bb4e82><a href="/pins" data-v-03bb4e82>
                沸点
                <span class="text" data-v-03bb4e82><!----></span></a></li> <li class="nav-item link-item book" data-v-03bb4e82><a href="/course" data-v-03bb4e82>
                课程
                <!----></a></li> <li class="nav-item link-item" data-v-03bb4e82><a href="/live" data-v-03bb4e82>
                直播
              </a></li> <li class="nav-item link-item" data-v-03bb4e82><a href="/events/all" data-v-03bb4e82>活动</a></li> <li class="nav-item link-item" data-v-03bb4e82><a href="/challenge" data-v-03bb4e82>
                竞赛
                <!----></a></li> <nav class="nav-item link-item" data-v-03bb4e82><a href="https://detail.youzan.com/show/goods/newest?kdt_id=104340304" target="_blank" rel="nofollow noopener noreferrer" class="jj-link nav-item link-item no-border" data-v-65b50b51 data-v-03bb4e82><span data-v-65b50b51 data-v-03bb4e82>商城</span></a> <!----></nav> <nav class="nav-item link-item download-icon" data-v-03bb4e82><a href="/app?utm_source=jj_nav" target="_blank" class="download-app no-border" data-v-03bb4e82>
                APP
              </a></nav> <nav class="nav-item link-item extension-icon" data-v-03bb4e82><a href="https://juejin.cn/extension?utm_source=jj_nav" target="_blank" rel="nofollow noopener noreferrer" class="jj-link broswer-extension no-border" data-v-65b50b51 data-v-03bb4e82><span data-v-65b50b51 data-v-03bb4e82>插件</span></a></nav> <!----></ul></li> <ul class="right-side-nav" data-v-03bb4e82><li class="search-add" data-v-03bb4e82><ul class="search-add-ul" data-v-03bb4e82><li class="nav-item search" data-v-03bb4e82><form role="search" class="search-form" data-v-03bb4e82><input type="search" maxlength="64" placeholder="" value="" class="search-input" data-v-03bb4e82> <div class="seach-icon-container" data-v-03bb4e82><svg width="18" height="18" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg" class="search-icon" data-v-03bb4e82 data-v-03bb4e82><path d="M12.4008 12.4008C14.744 10.0577 14.744 6.25871 12.4008 3.91556C10.0577 1.57242 6.25871 1.57242 3.91556 3.91556C1.57242 6.25871 1.57242 10.0577 3.91556 12.4008C6.25871 14.744 10.0577 14.744 12.4008 12.4008ZM12.4008 12.4008L15.5828 15.5828" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" data-v-03bb4e82 data-v-03bb4e82></path></svg></div> <!----> <div class="typehead" style="display:none;" data-v-03bb4e82><!----> <div class="title" data-v-03bb4e82><span data-v-03bb4e82>搜索历史</span> <span class="clear" data-v-03bb4e82>
                        清空
                      </span></div> <div class="list" data-v-03bb4e82></div></div></form></li> <li class="nav-item add creator-item" data-v-03bb4e82><div class="add-group" data-v-17cc1c49 data-v-03bb4e82><!----> <button class="add-btn" data-v-17cc1c49>
    创作者中心
  </button> <div class="more" data-v-17cc1c49><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="unfold12-icon" data-v-17cc1c49 data-v-17cc1c49><path d="M2.45025 4.82383C2.17422 4.49908 2.40501 4 2.83122 4H9.16878C9.59499 4 9.82578 4.49908 9.54975 4.82382L6.38097 8.5518C6.1813 8.7867 5.8187 8.7867 5.61903 8.5518L2.45025 4.82383Z" fill="white" data-v-17cc1c49 data-v-17cc1c49></path></svg> <div class="more-mask" data-v-17cc1c49></div> <div class="more-list" data-v-17cc1c49><ul class="menu" data-v-17cc1c49><li class="item" data-v-17cc1c49><div class="icon write-article" data-v-17cc1c49></div> <div class="title" data-v-17cc1c49>写文章</div></li><li class="item" data-v-17cc1c49><div class="icon issue-points" data-v-17cc1c49></div> <div class="title" data-v-17cc1c49>发沸点</div></li><li class="item" data-v-17cc1c49><div class="icon write-note" data-v-17cc1c49></div> <div class="title" data-v-17cc1c49>写笔记</div></li><li class="item" data-v-17cc1c49><div class="icon create-jcode" data-v-17cc1c49></div> <div class="title" data-v-17cc1c49>写代码</div></li><li class="item" data-v-17cc1c49><div class="icon drafts" data-v-17cc1c49></div> <div class="title" data-v-17cc1c49>草稿箱</div></li></ul> <div class="divider" data-v-17cc1c49></div> <div class="inspiration" data-v-17cc1c49><div class="info" data-v-17cc1c49><span class="title" data-v-17cc1c49>创作灵感</span> <span class="more-info" data-v-17cc1c49>
            查看更多
            <i class="icon byte-icon byte-icon--right" data-v-17cc1c49><svg t="1561636167146" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="404349" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M630.4 512L283.52 165.12a21.12 21.12 0 0 1 0-30.08l30.08-30.08a21.12 21.12 0 0 1 30.08 0l377.6 376.96a42.24 42.24 0 0 1 0 60.16l-377.6 376.96a21.12 21.12 0 0 1-30.08 0l-30.08-30.08a21.12 21.12 0 0 1 0-30.08z" p-id="404350"></path></svg></i></span></div> <div class="list" data-v-17cc1c49>  <div class="item" data-v-090682e2 data-v-17cc1c49><div class="xitu-skeleton xitu-skeleton-animated" data-v-090682e2><div class="xitu-skeleton-item" data-v-090682e2><!----> <div class="xitu-skeleton-content" data-v-090682e2><div class="xitu-skeleton-line" data-v-090682e2></div><div class="xitu-skeleton-line" data-v-090682e2></div><div class="xitu-skeleton-line" data-v-090682e2></div></div></div></div></div></div></div></div></div> <!----></div></li></ul></li> <li class="nav-item vip-entry" data-v-03bb4e82><div class="vip-title" data-v-03bb4e82><div class="vip-entry-img" data-v-03bb4e82><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ffd3e238ee7f46eab42bf88af17f5528~tplv-k3u1fbpfcp-image.image#?w=25&h=26&s=5968&e=svg&a=1&b=dacbbc" alt="vip" class="vip-img" data-v-03bb4e82> <!----></div> <div class="vip-words" data-v-03bb4e82>会员</div></div></li> <!----> <!----> <!----> <li class="nav-item auth hidden" data-v-03bb4e82><div class="login-button-wrap" data-v-03bb4e82><button class="login-button" data-v-03bb4e82>
                登录
                <div class="login-button-inner" data-v-03bb4e82><div class="login-button-line" data-v-03bb4e82></div>
                  注册
                </div></button> <!----></div></li></ul></ul></nav></div></header></div>  <main class="container main-container" style="max-width:1140px;" data-v-cd15ceae><div class="view column-view" data-v-cd15ceae data-v-0140422c><!----> <div class="main-area article-area" data-v-cd15ceae data-v-0140422c><article itemscope="itemscope" itemtype="http://schema.org/Article" data-entry-id="7273680143658287156" data-draft-id="7257058920920170553" data-original-type="0" class="article" data-v-0140422c><!----> <meta itemprop="headline" content="大模型分布式训练并行技术（五）-序列并行"> <meta itemprop="keywords" content="LLM"> <meta itemprop="datePublished" content="2023-09-01T14:30:08.000Z"> <meta itemprop="image" content="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-assets/icon/icon-128.png~tplv-t2oaga2asx-image.image"> <div itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="name" content="吃果冻不吐果冻皮"> <meta itemprop="url" content="https://juejin.cn/user/3642056016410728"></div> <div itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="掘金"> <div itemprop="logo" itemscope="itemscope" itemtype="https://schema.org/ImageObject"><meta itemprop="url" content="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-assets/icon/icon-white-180.png~tplv-t2oaga2asx-image.image"> <meta itemprop="width" content="180"> <meta itemprop="height" content="180"></div></div> <p class="article-title" data-v-0140422c>
            大模型分布式训练并行技术（五）-序列并行
            <!----> <!----></p> <div class="author-info-block block-hidden" data-v-0140422c><div class="author-info-box" data-v-0140422c><div class="author-name" data-v-0140422c><a href="/user/3642056016410728/posts" target="_blank" rel="" class="jj-link username username ellipsis" data-v-65b50b51 data-v-1800aadb data-v-0140422c><span class="name" style="max-width:160px;" data-v-65b50b51 data-v-1800aadb>
    吃果冻不吐果冻皮
  </span> <!----> <!----> <!----> </a></div> <div class="meta-box" data-v-0140422c><time datetime="2023-09-01T14:30:08.000Z" title="Fri Sep 01 2023 14:30:08 GMT+0000 (Coordinated Universal Time)" class="time" data-v-0140422c>
                    2023-09-01
                  </time> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg" class="read-icon" data-v-0140422c><path d="M7.90078 2.80078C4.49278 2.80078 1.74745 6.11672 0.800781 7.77469C1.74745 9.58339 4.49278 13.2008 7.90078 13.2008C11.3088 13.2008 14.0541 9.58339 15.0008 7.77469C14.0541 6.11672 11.3088 2.80078 7.90078 2.80078Z" stroke="currentColor" data-v-0140422c></path><circle cx="7.89922" cy="8.00078" r="2.2" stroke="currentColor" data-v-0140422c></circle></svg> <span class="views-count" data-v-0140422c>
                    3,236
                  </span> <span class="read-time" data-v-0140422c><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg" data-v-0140422c><rect width="16" height="16" fill="none" data-v-0140422c></rect><circle cx="8" cy="8" r="5.65625" stroke="#8A919F" data-v-0140422c></circle><path d="M7.69141 5.18652V8.30924H10.8141" stroke="#8A919F" stroke-linecap="round" stroke-linejoin="round" data-v-0140422c></path></svg>
                    阅读8分钟
                  </span> <!----></div></div> <div style="flex:1;" data-v-0140422c></div> <!----> <!----></div> <!----> <!----> <!----> <div id="article-root" itemprop="articleBody" class="main" data-v-0140422c><div class="article-viewer markdown-body cache result"><style>.markdown-body{word-break:break-word;line-height:1.75;font-weight:400;font-size:16px;overflow-x:hidden;color:#252933}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{line-height:1.5;margin-top:35px;margin-bottom:10px;padding-bottom:5px}.markdown-body h1{font-size:24px;line-height:38px;margin-bottom:5px}.markdown-body h2{font-size:22px;line-height:34px;padding-bottom:12px;border-bottom:1px solid #ececec}.markdown-body h3{font-size:20px;line-height:28px}.markdown-body h4{font-size:18px;line-height:26px}.markdown-body h5{font-size:17px;line-height:24px}.markdown-body h6{font-size:16px;line-height:24px}.markdown-body p{line-height:inherit;margin-top:22px;margin-bottom:22px}.markdown-body img{max-width:100%}.markdown-body hr{border:none;border-top:1px solid #ddd;margin-top:32px;margin-bottom:32px}.markdown-body code{word-break:break-word;border-radius:2px;overflow-x:auto;background-color:#fff5f5;color:#ff502c;font-size:.87em;padding:.065em .4em}.markdown-body code,.markdown-body pre{font-family:Menlo,Monaco,Consolas,Courier New,monospace}.markdown-body pre{overflow:auto;position:relative;line-height:1.75}.markdown-body pre>code{font-size:12px;padding:15px 12px;margin:0;word-break:normal;display:block;overflow-x:auto;color:#333;background:#f8f8f8}.markdown-body a{text-decoration:none;color:#0269c8;border-bottom:1px solid #d1e9ff}.markdown-body a:active,.markdown-body a:hover{color:#275b8c}.markdown-body table{display:inline-block!important;font-size:12px;width:auto;max-width:100%;overflow:auto;border:1px solid #f6f6f6}.markdown-body thead{background:#f6f6f6;color:#000;text-align:left}.markdown-body tr:nth-child(2n){background-color:#fcfcfc}.markdown-body td,.markdown-body th{padding:12px 7px;line-height:24px}.markdown-body td{min-width:120px}.markdown-body blockquote{color:#666;padding:1px 23px;margin:22px 0;border-left:4px solid #cbcbcb;background-color:#f8f8f8}.markdown-body blockquote:after{display:block;content:""}.markdown-body blockquote>p{margin:10px 0}.markdown-body ol,.markdown-body ul{padding-left:28px}.markdown-body ol li,.markdown-body ul li{margin-bottom:0;list-style:inherit}.markdown-body ol li .task-list-item,.markdown-body ul li .task-list-item{list-style:none}.markdown-body ol li .task-list-item ol,.markdown-body ol li .task-list-item ul,.markdown-body ul li .task-list-item ol,.markdown-body ul li .task-list-item ul{margin-top:0}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:3px}.markdown-body ol li{padding-left:6px}.markdown-body .contains-task-list{padding-left:0}.markdown-body .task-list-item{list-style:none}@media (max-width:720px){.markdown-body h1{font-size:24px}.markdown-body h2{font-size:20px}.markdown-body h3{font-size:18px}}</style><style data-highlight data-highlight-key="juejin">.markdown-body pre,.markdown-body pre>code.hljs{color:#333;background:#f8f8f8}.hljs-comment,.hljs-quote{color:#998;font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#333;font-weight:700}.hljs-literal,.hljs-number,.hljs-tag .hljs-attr,.hljs-template-variable,.hljs-variable{color:teal}.hljs-doctag,.hljs-string{color:#d14}.hljs-section,.hljs-selector-id,.hljs-title{color:#900;font-weight:700}.hljs-subst{font-weight:400}.hljs-class .hljs-title,.hljs-type{color:#458;font-weight:700}.hljs-attribute,.hljs-name,.hljs-tag{color:navy;font-weight:400}.hljs-link,.hljs-regexp{color:#009926}.hljs-bullet,.hljs-symbol{color:#990073}.hljs-built_in,.hljs-builtin-name{color:#0086b3}.hljs-meta{color:#999;font-weight:700}.hljs-deletion{background:#fdd}.hljs-addition{background:#dfd}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}</style><p><strong>本文为稀土掘金技术社区首发签约文章，30天内禁止转载，30天后未获授权禁止转载，侵权必究！</strong></p>
<p>近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡模式已经无法满足超大模型进行训练的要求。因此，我们需要基于单机多卡、甚至是多机多卡进行分布式大模型的训练。</p>
<p>而利用AI集群，使深度学习算法更好地从大量数据中高效地训练出性能优良的大模型是分布式机器学习的首要目标。为了实现该目标，一般需要根据硬件资源与数据/模型规模的匹配情况，考虑对计算任务、训练数据和模型进行划分，从而进行分布式存储和分布式训练。因此，分布式训练相关技术值得我们进行深入分析其背后的机理。</p>
<p>下面主要对大模型进行分布式训练的并行技术进行讲解，本系列大体分八篇文章进行讲解。</p>
<ul>
<li><a href="https://link.juejin.cn?target=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F598714869" target="_blank" title="https://zhuanlan.zhihu.com/p/598714869" ref="nofollow noopener noreferrer">大模型分布式训练并行技术（一）-概述</a></li>
<li><a href="https://link.juejin.cn?target=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F650002268" target="_blank" title="https://zhuanlan.zhihu.com/p/650002268" ref="nofollow noopener noreferrer">大模型分布式训练并行技术（二）-数据并行</a></li>
<li><a href="https://juejin.cn/post/7262274383287484476" target="_blank" title="https://juejin.cn/post/7262274383287484476">大模型分布式训练并行技术（三）-流水线并行</a></li>
<li><a href="https://juejin.cn/post/7269698032655728640" target="_blank" title="https://juejin.cn/post/7269698032655728640">大模型分布式训练并行技术（四）-张量并行</a></li>
<li>大模型分布式训练并行技术（五）-序列并行</li>
<li>大模型分布式训练并行技术（六）-多维混合并行</li>
<li>大模型分布式训练并行技术（七）-自动并行</li>
<li>大模型分布式训练并行技术（八）-MOE并行</li>
</ul>
<p>本文为分布式训练并行技术的第五篇：序列并行。目前，有两篇关于序列并行的文章：</p>
<ul>
<li>第一篇是 Colossal-AI 发表的论文：Sequence Parallelism: Long Sequence Training from System Perspective</li>
<li>第二篇是 Megatron-LM 发表的论文：Reducing Activation Recomputation in Large Transformer Models</li>
</ul>
<p>虽然两者都叫序列并行（Sequence Parallelism），但是实际上解决的问题、方法都不一样。前者主要是解决模型的输入长度(sequence length)限制，而后者是主要是减少模型显存的。下面将一一讲对其进行解。</p>
<h2 data-id="heading-0">序列并行（Colossal-AI）</h2>
<p>Colossal-AI 序列并行诞生的背景是 self-attention 的内存需求是输入长度（sequence length）的2次方。其复杂度为 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>，其中，n 是序列长度。换言之，长序列数据将增加中间activation内存使用量，从而限制设备的训练能力。</p>
<p>而现有的工作侧重于从算法的角度降低时间和空间复杂度。因此，作者提出了序列并行，这是一种内存高效的并行方法，可以帮助我们打破输入序列长度限制，并在 GPU 上有效地训练更长的序列；同时，该方法与大多数现有的并行技术兼容（例如：数据并行、流水线并行和张量并行）。</p>
<p>更重要的是，我们不再需要单个设备来保存整个序列。 即在稀疏注意力的情况下，我们的序列并行使我们能够训练具有无限长序列的 Transformer。</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dd8f31a28f504891af7d0379064f20ac~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>具体来说，我们将输入序列分割成多个块，并将每个块输入到其相应的设备（即 GPU）中。为了计算注意力输出，我们将环状通信与自注意力计算相结合，并提出了环自注意力（RSA）如下图所示。</p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f8d4b9f9a76248879a6c19b4487802c4~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>实验表明，当按批量大小和序列长度进行缩放时，序列并行表现良好。</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a5dbc208b8b44896b2a6dd571cbae8cc~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/db70e40767e74a1ca61d8c5710f4fd18~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>当扩展到 64 个 NVIDIA P100 GPU 时，与张量并相比，该法分别实现了 13.7 倍和 3.0 倍的最大批量大小和序列长度。</p>
<p>通过稀疏注意力，序列可以处理具有超过 114K 个 Token 的序列，这比现有的在单个设备上保存整个序列的稀疏注意力运行长度超过 27 倍。</p>
<p>除此之外，与张量并行和流水线并行不同，序列并行不受超参数（例如：
注意力头数、层数）限制。 因此，只要序列长度能被序列并行大小整除，我们的序列并行就可以使用。</p>
<h2 data-id="heading-1">序列并行（Megatron-LM）</h2>
<p>Megatron-LM 的初衷是考虑通过其他方式分摊张量并行中无法分摊的显存，因此提出了序列并行的方法。</p>
<p>虽然 Megatron-LM 引用了 Colossal-AI 的序列并行的这篇文章，但是这两者其实并不是一个东西。</p>
<p>Megatron-LM 只是借用了 Colossal-AI 把 Sequence 这个维度进行平均划分的思想。在 张量的基础上，将 Transformer 层中的 LayerNorm 以及 Dropout 的输入按输入长度（Sequence Length）维度进行了切分，使得各个设备上面只需要做一部分的 Dropout 和 LayerNorm 即可。</p>
<p>这样做的好处有：</p>
<ol>
<li>LayerNorm 和 Dropout 的计算被平摊到了各个设备上，减少了计算资源的浪费；</li>
<li>LayerNorm 和 Dropout 所产生的激活值也被平摊到了各个设备上，进一步降低了显存开销。</li>
</ol>
<p>在 Megatron-LM 序列并行的这篇论文中，首先分析了 Transformer 模型运行时的显存占用情况。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c3bfb065502647b4a7428c8d31b29886~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>假设输入长度为 s ，batch size为 b ，hidden dim为 h ，attention head数量为 a ，则每一层 Transformer（上图的灰色区域）的显存占用：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ac973d75e03d411dafe809a337ba923a~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>当我们开启了张量并行之后，上述Transformer层中的部分模块的显存可以被分摊到不同的设备之间。如下图所示，不能被分摊的部分主要是两个 LayerNorm 块的输入和输出： 4bsh ；两个 dropout mask 块：2bsh ；一共是 10bsh。</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/10fb4f441b4642ffa815168ed2132921~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>假设张量并行大小为t，因此，每个设备每一层 Transformer 的显存占用为：</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/746ec1f345c14a119b33e7e4dc1608da~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>下面开启张量并行以及序列并行，Transformer 层中的 LayerNorm 和 Dropout 块也会被切分，对 Tensor 在 Sequence 维度进行切分，切分数量等于张量并行大小。</p>
<p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d975ec75f96c492e8f73ae4a41c7d1a2~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>每个设备每一层 Transformer 的显存占用为：</p>
<p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/34116a015e794a7eaa61d7eea16c2a52~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>当然，做了额外的切分就会带来通信方式的改变。</p>
<p>Transformer 层的张量并行通信是由正向传播两个All-Reduce以及反向传播两个All-Reduce组成。</p>
<p>而序列并行由于对 Sequence 维度进行了划分，All-Reduce在这里已经不合适了。</p>
<p>为了收集在各个设备上进行序列并行所产生的结果，需要插入All-Gather算子；而为了使得张量并行所产生的结果可以传入序列并行层，需要插入Reduce-Scatter算子。</p>
<p>在下图中， <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span></span></span> 所代表的就是前向传播的 All-Gather，反向传播的 Reduce-Scatter，<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>g</mi><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">\overline{g}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.825em;vertical-align:-0.1944em;"></span><span class="mord overline"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6306em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span></span></span><span style="top:-3.5506em;"><span class="pstrut" style="height:3em;"></span><span class="overline-line" style="border-bottom-width:0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span></span> 则是相反的操作。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a44912c47ef24fd681ed0ca6cd1ac38b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<p>因此，我们可以清楚地看到，在 Megatron-LM 同时开启序列并行和模型并行时，每一个 Transformer 层完成一次前向传播和反向传播一共有 4 个 All-Gather 和 4 个 Reduce-Scatter 算子。乍一看，通信的操作比 Megatron-LM 仅开启张量并行多，但其实不然。因为，一个All-Reduce就相当于一个 Reduce-Scatter 和一个 All-Gather ，所以他们的总通信量是一样的。</p>
<p>通过添加序列并行并没有增加额外的通信开销，反而在后向传播代码的实现上，还把 Reduce-Scatter 和权重梯度的计算做了重叠，进一步减少了通信所占用的时间，使得提高设备的FLOPs Utilization成为了可能。</p>
<p>通过对Transformer层中所有Activation的消耗进行计算，发现在Transformer层里有一些操作是产生的激活值大，但计算量小。因此，就考虑干掉这一部分的激活值，通过选择性的进行激活重新计算（Selective Activation Recomputation）来进一步降低显存。与此同时，其他的激活值就通通保存，以节省重计算量。</p>
<p>通过对激活值的占比分析，序列并行降低了4成左右的激活值开销。选择性激活重新计算（selective activation recompute）也降低了4成左右的激活值开销。当两个特性都打开的时候，总共可以降低8成左右的激活值开销，尽管比全部激活值重计算的结果要稍高，但是在吞吐率上的提升还是非常的明显的。</p>
<p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2eaa429312ed4d4fa658536bc26b102e~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="image.png" loading="lazy"></p>
<h2 data-id="heading-2">Pytorch 中的序列并行</h2>
<p>上一篇张量并行的文章中提到 Pytorch 从 2.0.0 开始已经开始支持张量并行了。参考 Megatron-LM 的序列并行，目前在 Pytorch 中，也已经支持序列并行了，不过还没有 Release，具体示例如下所示：</p>
<pre><code class="hljs language-python" lang="python"><span class="hljs-comment"># 通过设备网格根据给定的 world_size 创建分片计划</span>
device_mesh = DeviceMesh(<span class="hljs-string">"cuda"</span>, torch.arange(<span class="hljs-number">0</span>, args.world_size))

<span class="hljs-comment"># 创建模型并移动到GPU</span>
model = ToyModel().cuda(rank)

<span class="hljs-comment"># 为并行化模块创建优化器</span>
LR = <span class="hljs-number">0.25</span>
optimizer = torch.optim.SGD(model.parameters(), lr=LR)

<span class="hljs-comment"># 根据给定的并行风格并行化模块，这里指定为序列并行</span>
model = parallelize_module(model, device_mesh, SequenceParallel())

<span class="hljs-comment"># 对分片模块执行多次前向/后向传播和优化器对参数进行更新。</span>
<span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(args.iter_nums):
    <span class="hljs-comment"># 对于 SP，所有rank的输入可以不同。</span>
    inp = torch.rand(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>).cuda(rank)
    output = model(inp)
    output.<span class="hljs-built_in">sum</span>().backward()
    optimizer.step()
</code></pre>
<h2 data-id="heading-3">结语</h2>
<p>总的来说，Colossal-AI 的序列并行是为了打破单设备上序列长度的限制。而 Megatron-LM 的序列并行是在显存上面下了功夫，可以用更少的设备去运行大模型。除此之外，从文章细节里面可以看到，部分的计算的冗余被消除了，且重叠了一部分的通信，使得设备可以花更多的时间用于计算上面。虽然，Colossal-AI 和 Megatron-LM 都有序列并行，但是两者解决的问题、方法都不一样。除此之外，在Pytorch中，也已经支持序列并行了。</p>
<p>码字不易，如果觉得我的文章能够能够给您带来帮助，期待您的点赞收藏加关注~~</p></div> <!----></div></article> <div class="article-end" data-v-cd15ceae data-v-0140422c><div class="rank-entry-bottom" data-v-cd15ceae data-v-0140422c><!----></div> <div class="tag-list-box" data-v-cd15ceae data-v-0140422c><!----><!----><!----></div></div> <!----><!----><!----><!----><!----></div> <div id="sidebar-container" class="sidebar article-sidebar" data-v-2c12cc88 data-v-0140422c><div class="sidebar-block author-block author-block-container pure" data-v-7e7e812a data-v-a6d177e4 data-v-2c12cc88><a href="/user/3642056016410728/posts" target="_blank" rel="" class="jj-link user-item item" data-v-65b50b51 data-v-a6d177e4><div class="avatar jj-avatar avatar" data-v-03256cc6 data-v-a6d177e4><img loading="eager" src="https://p3-passport.byteacctimg.com/img/user-avatar/61eb73e2e7c5171e52273a81f15dd39f~200x200.awebp" alt="avatar" class="lazy avatar-img immediate" data-v-5244ef91 data-v-03256cc6> </div> <div class="info-box" style="visibility:hidden;" data-v-65b50b51 data-v-a6d177e4><span to="[object Object]" blank="true" class="username" data-v-1800aadb data-v-a6d177e4><span class="name" style="max-width:128px;" data-v-1800aadb>
    吃果冻不吐果冻皮
  </span> <span to="" blank="true" class="rank" data-v-23743940 data-v-1800aadb><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAA8AQMAAAAAMksxAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAA5JREFUKM9jGAWjAAcAAAIcAAE27nY6AAAAAElFTkSuQmCC" alt="创作等级LV.5" title="创作等级LV.5" class="lazy" style="aspect-ratio:NaN;" data-v-5244ef91 data-v-23743940></span> <!----> <!----> </span> <div title="🏆掘金签约作者｜人工智能方向" class="position" data-v-65b50b51 data-v-a6d177e4>
        🏆掘金签约作者｜人工智能方向
      </div> <div class="extra-container" data-v-65b50b51 data-v-a6d177e4><!----> </div></div></a> <div class="count-container" data-v-7e7e812a data-v-a6d177e4><a href="/user/3642056016410728/posts" target="_blank" rel="" class="jj-link stat-item item" data-v-65b50b51 data-v-a6d177e4><div class="count" style="display:none;" data-v-65b50b51 data-v-a6d177e4>
        325
      </div> <div data-v-65b50b51 data-v-a6d177e4>文章</div></a> <a href="/user/3642056016410728/posts" target="_blank" rel="" class="jj-link stat-item item" data-v-65b50b51 data-v-a6d177e4><div class="count" style="display:none;" data-v-65b50b51 data-v-a6d177e4>
        426k
      </div> <div data-v-65b50b51 data-v-a6d177e4>阅读</div></a> <a href="/user/3642056016410728/followers" target="_blank" rel="" class="jj-link stat-item item" data-v-65b50b51 data-v-a6d177e4><div class="count" style="display:none;" data-v-65b50b51 data-v-a6d177e4>
        477
      </div> <div data-v-65b50b51 data-v-a6d177e4>粉丝</div></a></div> <div class="operate-btn hidden" style="position:relative;z-index:2;min-height:36px;" data-v-7e7e812a data-v-a6d177e4><!----><!----><!----></div> <!----></div> <div class="sticky-block-box" data-v-2c12cc88><nav class="article-catalog catalog-block none" data-v-6239701c data-v-16ed86c3 data-v-2c12cc88><div class="catalog-title" data-v-6239701c><div data-v-6239701c>目录</div> <div class="direction" data-v-6239701c><div class="word" data-v-6239701c>收起</div> <svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-rotate" data-v-6239701c data-v-6239701c><g id="&amp;#229;&amp;#177;&amp;#149;&amp;#229;&amp;#188;&amp;#128;" data-v-6239701c data-v-6239701c><path id="&amp;#232;&amp;#183;&amp;#175;&amp;#229;&amp;#190;&amp;#132;" fill-rule="evenodd" clip-rule="evenodd" d="M5.99854 7.93206L10.0644 3.86619C10.162 3.76856 10.3203 3.76856 10.418 3.86619L10.7715 4.21975C10.8691 4.31738 10.8691 4.47567 10.7715 4.5733L6.35209 8.99272C6.15683 9.18798 5.84025 9.18798 5.64498 8.99272L1.22557 4.5733C1.12794 4.47567 1.12794 4.31738 1.22557 4.21975L1.57912 3.86619C1.67675 3.76856 1.83504 3.76856 1.93267 3.86619L5.99854 7.93206Z" fill="#8A919F" data-v-6239701c data-v-6239701c></path></g></svg></div></div> <div class="catalog-body unfold" data-v-6239701c><ul class="catalog-list" style="margin-top:0px;" data-v-6239701c><li class="item d1" data-v-6239701c><div class="a-container"><a href="#heading-0" title="序列并行（Colossal-AI）" class="catalog-aTag d1-aTag-title">
      序列并行（Colossal-AI）
    </a></div> <!----></li><li class="item d1" data-v-6239701c><div class="a-container"><a href="#heading-1" title="序列并行（Megatron-LM）" class="catalog-aTag d1-aTag-title">
      序列并行（Megatron-LM）
    </a></div> <!----></li><li class="item d1" data-v-6239701c><div class="a-container"><a href="#heading-2" title="Pytorch 中的序列并行" class="catalog-aTag d1-aTag-title">
      Pytorch 中的序列并行
    </a></div> <!----></li><li class="item d1" data-v-6239701c><div class="a-container"><a href="#heading-3" title="结语" class="catalog-aTag d1-aTag-title">
      结语
    </a></div> <!----></li></ul></div></nav> <!----> <!----> <div class="sidebar-block shadow" data-v-7e7e812a data-v-79d288d1 data-v-2c12cc88><div class="block-title" data-v-7e7e812a>相关推荐</div> <div class="block-body" data-v-7e7e812a><div class="entry-list" data-v-7e7e812a data-v-79d288d1><a href="/post/7300499502758494217" target="_blank" rel="" title="大模型参数高效微调技术原理综述（六）-MAM Adapter、UniPELT" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型参数高效微调技术原理综述（六）-MAM Adapter、UniPELT</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>602阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>0点赞</div></div></a><a href="/post/7280861248421019659" target="_blank" rel="" title="大模型分布式训练并行技术（七）-自动并行" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型分布式训练并行技术（七）-自动并行</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>3.2k阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>15点赞</div></div></a><a href="/post/7242217556623179833" target="_blank" rel="" title="大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>2.0k阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>5点赞</div></div></a><a href="/post/7242290406636781626" target="_blank" rel="" title="大模型参数高效微调技术原理综述（三）-P-Tuning、P-Tuning v2" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型参数高效微调技术原理综述（三）-P-Tuning、P-Tuning v2</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>5.4k阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>2点赞</div></div></a><a href="/post/7289661052806594618" target="_blank" rel="" title="大模型分布式训练并行技术（八）-MOE并行" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型分布式训练并行技术（八）-MOE并行</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>3.4k阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>3点赞</div></div></a><a href="/post/7266044346527957007" target="_blank" rel="" title="大模型参数高效微调技术实战（六）-IA3" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型参数高效微调技术实战（六）-IA3</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>888阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>4点赞</div></div></a><a href="/post/7242677017057755191" target="_blank" rel="" title="大模型参数高效微调技术原理综述（四）-Adapter Tuning及其变体" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型参数高效微调技术原理综述（四）-Adapter Tuning及其变体</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>2.5k阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>3点赞</div></div></a><a href="/post/7254001262646738981" target="_blank" rel="" title="大模型分布式训练并行技术（二）-数据并行" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型分布式训练并行技术（二）-数据并行</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>6.5k阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>10点赞</div></div></a><a href="/post/7277799192966578176" target="_blank" rel="" title="大模型分布式训练并行技术（六）-多维混合并行" class="jj-link item" data-v-65b50b51 data-v-79d288d1><div class="entry-title" data-v-65b50b51 data-v-79d288d1>大模型分布式训练并行技术（六）-多维混合并行</div> <div class="entry-meta-box" data-v-65b50b51 data-v-79d288d1><!----> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>5.2k阅读</div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1> · </div> <div class="entry-meta" data-v-65b50b51 data-v-79d288d1>10点赞</div></div></a></div></div></div> <!----></div> <div class="adverts-list" data-v-0eca8145 data-v-2c12cc88></div> <!----></div> <!----> <!----> <div id="article-suspended-panel" data-v-cd15ceae data-v-0140422c></div></div> <!----><!----><!----><!----><!----><!----><!----></main> <!----></div> <!----> <div class="global-component-box"><!----></div> <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----> <!----><!----><!----><!----><!----><!----><!----><!----><!----><!----><!----></div></div></div><script>window.__NUXT__=(function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O){u.loading=a;u.skeleton=d;u.cursor=f;u.data=[];u.total=b;u.hasMore=d;F.id=x;F.self_description=n;F.followed=a;F.viewerIsFollowing=n;F.community=n;F.subscribedTagCount=b;F.wroteBookCount=b;F.boughtBookCount=b;F.isBindedPhone=a;F.level=t;F.user_id=x;F.user_name=D;F.company=e;F.job_title="🏆掘金签约作者｜人工智能方向";F.avatar_large="https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image";F.description="公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。";F.followee_count=h;F.follower_count=477;F.post_article_count=325;F.digg_article_count=17;F.got_digg_count=457;F.got_view_count=426334;F.post_shortmsg_count=9;F.digg_shortmsg_count=b;F.isfollowed=a;F.favorable_author=b;F.power=E;F.study_point=b;F.university={university_id:f,name:e,logo:e};F.major={major_id:f,parent_id:f,name:e};F.student_status=b;F.select_event_count=b;F.select_online_course_count=b;F.identity=b;F.is_select_annual=d;F.select_annual_rank=b;F.annual_list_type=b;F.extraMap={};F.is_logout=b;F.annual_info=[];F.account_amount=b;F.user_growth_info={user_id:3642056016410728,jpower:E,jscore:1976,jpower_level:t,jscore_level:t,jscore_title:"先锋掘友",author_achievement_list:[g],vip_level:b,vip_title:e,jscore_next_level_score:2000,jscore_this_level_mini_score:500,vip_score:b};F.is_vip=a;F.become_author_days=b;F.collection_set_article_count=b;F.recommend_article_count_daily=b;F.article_collect_count_daily=b;F.user_priv_info={administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b};F.juejinPower=E;F.jobTitle="🏆掘金签约作者｜人工智能方向";F.roles={isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a};F.username=D;F.blogAddress=n;F.selfDescription="公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。";F.beLikedCount=457;F.beReadCount=426334;F.followerCount=477;F.followingCount=h;F.collectionCount=b;F.createdCollectionCount=b;F.followingCollectionCount=b;F.postedPostsCount=325;F.pinCount=9;F.likedArticleCount=17;F.likedPinCount=b;F.avatar="https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image";F.latestLoginedInAt=c;F.createdAt=c;F.updatedAt=c;F.phoneNumber=e;F.titleDescription=e;F.followeesCount=h;F.applyEventCount=b;F.need_lead=b;F.followTopicCnt=b;return {layout:"default",data:[{renderPost:d}],fetch:[{queryString:e,isShowUserDropdownList:a,isShowAddMoreList:a,isFocus:a,isPhoneMenuShow:a,visibleBadge:a,placeholder:e,hiddenProperty:"hidden",searchHistoryVisible:a,searchHistoryItems:[],tabBadge:c,isChangePlaceholder:d,showMallBridge:a,removeSearchInputKeyupListener:c,logoImg:"\u002F\u002Flf-web-assets.juejin.cn\u002Fobj\u002Fjuejin-web\u002Fxitu_juejin_web\u002Fe08da34488b114bd4c665ba2fa520a31.svg"}],error:c,state:{view:{activityIndex:{activityList:[],pageInfo:{hasNextPage:a,endCursor:e},afterPosition:e,activityListIsLoading:d,activityListIsError:a,userActivityList:[],placeholder:e,actionType:{FETCH:"@\u002Fview\u002Factivity-index\u002FFETCH",FETCH_RECOMMEND_LIST:"@\u002Fview\u002Factivity-index\u002FFETCH_RECOMMEND_LIST",RESET_ACTIVITY_LIST:"@\u002Fview\u002Factivity-index\u002FRESET_ACTIVITY_LIST",FETCH_USER_ACTIVITY_LIST:"@\u002Fview\u002Factivity-index\u002FFETCH_USER_ACTIVITY_LIST",FETCH_NEW_COUNT:"@\u002Fview\u002Factivity-index\u002FFETCH_NEW_COUNT",DELETE_ACTIVITY:"@\u002Fview\u002Factivity-index\u002FDELETE_ACTIVITY",TOGGLE_FOLLOW_USER:"@\u002Fview\u002Factivity-index\u002FTOGGLE_FOLLOW_USER",FETCH_ENTRY_COMMENT_LIST:"@\u002Fview\u002Factivity-index\u002FFETCH_ENTRY_COMMENT_LIST",UPDATE_LIST_LOADING:"@\u002Fview\u002Factivity-index\u002FUPDATE_LIST_LOADING",RESET:"@\u002Fview\u002Factivity-index\u002FRESET"},hotList:{list:[],after:e,loading:a,hasNextPage:a,actionType:{UPDATE_STATE:"@\u002Fview\u002Factivity-index\u002Fhot-list\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Factivity-index\u002Fhot-list\u002FFETCH_MORE",FETCH:"@\u002Fview\u002Factivity-index\u002Fhot-list\u002FFETCH",RESET:"@\u002Fview\u002Factivity-index\u002Fhot-list\u002FRESET"}},sidebar:{bannerList:[],actionType:{RESET:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002FRESET",UPDATE_STATE:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002FUPDATE_STATE",FETCH_BANNER:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002FFETCH_BANNER"},recommend:{pageSize:h,page:b,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-topic-list\u002FUPDATE",FETCH:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-topic-list\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-topic-list\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-topic-list\u002FFETCH_MORE",RESET:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-topic-list\u002FRESET"},after:b},followed:{pageSize:h,page:b,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Ffollowed-topic-list\u002FUPDATE",FETCH:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Ffollowed-topic-list\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Ffollowed-topic-list\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Ffollowed-topic-list\u002FFETCH_MORE",RESET:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Ffollowed-topic-list\u002FRESET"},after:b},recommendPin:{list:[],after:e,loading:a,hasNextPage:d,actionType:{UPDATE_STATE:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-pin-list\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-pin-list\u002FFETCH_MORE",FETCH:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-pin-list\u002FFETCH",RESET:"@\u002Fview\u002Factivity-index\u002Fsidebar\u002Frecommend-pin-list\u002FRESET"}}},topicPinList:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Factivity-index\u002Ftopic-pin-list\u002FUPDATE",FETCH:"@\u002Fview\u002Factivity-index\u002Ftopic-pin-list\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Factivity-index\u002Ftopic-pin-list\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Factivity-index\u002Ftopic-pin-list\u002FFETCH_MORE",RESET:"@\u002Fview\u002Factivity-index\u002Ftopic-pin-list\u002FRESET"},topicId:e,navList:[{type:m,name:m,title:"推荐 ",id:m},{type:p,name:p,title:"热门 ",id:p},{type:s,name:s,title:"关注 ",id:s},{type:i,name:"opensource",title:"开源推荐 ",id:"5c09ea2b092dcb42c740fe73"},{type:i,name:"recruitment",title:"内推招聘",id:"5abb61e1092dcb4620ca3322"},{type:i,name:"dating",title:"掘金相亲",id:"5abcaa67092dcb4620ca335c"},{type:i,name:"slacking",title:"上班摸鱼",id:"5c106be9092dcb2cc5de7257"},{type:i,name:"app",title:"应用安利",id:"5b514af1092dcb61bd72800d"},{type:i,name:"tool",title:"开发工具",id:"5abb67d2092dcb4620ca3324"},{type:i,name:"news",title:"New资讯",id:"5c46a17f092dcb4737217152"}],sortType:q}},search:{search_result_from:b,query:e,list:[],linkList:[],loading:a,skeleton:d,actionType:{FETCH:"@\u002Fview\u002Fsearch\u002FFETCH",FETCH_MORE:"@\u002Fview\u002Fsearch\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fsearch\u002FRESET"}},columnIndex:{list:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002FcolumnIndex\u002Flist\u002FUPDATE",FETCH:"@\u002Fview\u002FcolumnIndex\u002Flist\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002FcolumnIndex\u002Flist\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002FcolumnIndex\u002Flist\u002FFETCH_MORE",RESET:"@\u002Fview\u002FcolumnIndex\u002Flist\u002FRESET"},sort:r,category:"all"},hotList:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002FcolumnIndex\u002FhotList\u002FUPDATE",FETCH:"@\u002Fview\u002FcolumnIndex\u002FhotList\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002FcolumnIndex\u002FhotList\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002FcolumnIndex\u002FhotList\u002FFETCH_MORE",RESET:"@\u002Fview\u002FcolumnIndex\u002FhotList\u002FRESET"}}},timelineIndex:{tdkTemplates:[],categoryNavList:[],tagNavList:[],splitTagList:[],timelineAdList:[],list:[],sort:q,category:m,categoryId:e,tagId:e,tag:"全部",actionType:{FETCH_TIMELINE_LIST:"@\u002Fview\u002FtimelineIndex\u002FFETCH_TIMELINE_LIST",FETCH_CATEGORY_LIST:"@\u002Fview\u002FtimelineIndex\u002FFETCH_CATEGORY_LIST",FETCH_TAG_LIST:"@\u002Fview\u002FtimelineIndex\u002FFETCH_TAG_LIST",DELETE_ENTRY:"@\u002Fview\u002FtimelineIndex\u002FDELETE_ENTRY",DELETE_USER_ENTRIES:"@\u002Fview\u002FtimelineIndex\u002FDELETE_USER_ENTRIES",DELETE_TAG_ENTRIES:"@\u002Fview\u002FtimelineIndex\u002FDELETE_TAG_ENTRIES",FETCH_MORE:"@\u002Fview\u002FtimelineIndex\u002FFETCH_MORE",FETCH:"@\u002Fview\u002FtimelineIndex\u002FFETCH",RESET:"@\u002Fview\u002FtimelineIndex\u002FRESET"},serverRenderTimelineList:a,timelineList:{list:[],cursor:f,skeleton:d,loading:a,hasMore:d,categoryId:e,tagId:e,sort:e,actionType:{UPDATE_STATE:"timeline-list\u002FUPDATE_STATE",FETCH_MORE:"timeline-list\u002FFETCH_MORE",FETCH:"timeline-list\u002FFETCH",RESET:"timeline-list\u002FRESET"}},recommendList:{list:[],cursor:f,sort:e,loading:a,skeleton:d,hasMore:d,actionType:{UPDATE_STATE:"recommend-list\u002FUPDATE_STATE",FETCH_MORE:"recommend-list\u002FFETCH_MORE",FETCH:"recommend-list\u002FFETCH",RESET:"recommend-list\u002FRESET"}},followingList:{list:[],cursor:f,skeleton:d,loading:a,hasMore:d,actionType:{UPDATE_STATE:"following-list\u002FUPDATE_STATE",FETCH_MORE:"following-list\u002FFETCH_MORE",FETCH:"following-list\u002FFETCH",RESET:"following-list\u002FRESET"}}},subscribe:{subscribed:{list:[],cursor:f,skeleton:d,loading:a,hasMore:a,actionType:{UPDATE_STATE:"view\u002Fsubscribe\u002Fsubscribed\u002Flist\u002FUPDATE_STATE",FETCH_MORE:"view\u002Fsubscribe\u002Fsubscribed\u002Flist\u002FFETCH_MORE",FETCH:"view\u002Fsubscribe\u002Fsubscribed\u002Flist\u002FFETCH",RESET:"view\u002Fsubscribe\u002Fsubscribed\u002Flist\u002FRESET"}},all:{list:[],cursor:f,loading:a,skeleton:d,hasMore:a,linkList:e,actionType:{UPDATE_STATE:"view\u002Fsubscribe\u002Fall\u002Flist\u002FUPDATE_STATE",FETCH_MORE:"view\u002Fsubscribe\u002Fall\u002Flist\u002FFETCH_MORE",FETCH:"view\u002Fsubscribe\u002Fall\u002Flist\u002FFETCH",RESET:"view\u002Fsubscribe\u002Fall\u002Flist\u002FRESET"}}},entryPublic:{entry:{user:{}},relatedEntryList:[],relatedCollectionList:[],actionType:{FETCH:"@\u002Fview\u002FentryPublic\u002FFETCH",RESET:"@\u002Fview\u002FentryPublic\u002FRESET"}},user:{user:{},serverRendered:a,userAnnuals:[],actionType:{FETCH:"@\u002Fview\u002Fuser\u002FFETCH",RESET:"@\u002Fview\u002Fuser\u002FRESET",UPDATE:"@\u002Fview\u002Fuser\u002FUPDATE",FETCH_ANNUALS:"@\u002Fview\u002Fuser\u002FFETCH_ANNUALS"},detailList:{actionType:{RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FRESET"},likeList:{list:[],cursor:f,hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FlikePostList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FlikePostList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FlikePostList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FlikePostList\u002FRESET"}},postList:{list:[],hasMore:a,skeleton:a,loading:a,sort:r,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FpostList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FpostList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FpostList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FpostList\u002FRESET"}},searchList:{list:[],hasMore:a,skeleton:a,loading:a,key_word:e,search_type:b,cursor:f,isPostSearch:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FsearchList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FsearchList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FsearchList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FsearchList\u002FRESET"}},tagList:{list:[],loading:a,skeleton:a,hasMore:a,cursor:f,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FtagList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FtagList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FtagList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FtagList\u002FRESET"}},collectionList:{list:[],userId:e,skeleton:a,hasMore:a,cursor:f,type:w,loading:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FRESET",TOGGLE_FOLLOW_COLLECTION:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FTOGGLE_FOLLOW_COLLECTION",FOLLOW_COLLECTION:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FFOLLOW_COLLECTION",UNFOLLOW_COLLECTION:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FUNFOLLOW_COLLECTION",DELELTE_COLLECTION:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FDELELTE_COLLECTION",ADD_COLLECTION:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FADD_COLLECTION",EDIT_COLLECTION:"@\u002Fview\u002Fuser\u002FdetailList\u002FcollectionList\u002FEDIT_COLLECTION"}},followerList:{list:[],cursor:f,hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowerList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowerList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowerList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowerList\u002FRESET"}},followingList:{list:[],cursor:f,hasMore:a,skeleton:a,loading:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowingList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowingList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowingList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowingList\u002FRESET"}},followingTeamsList:{list:[],cursor:f,hasMore:a,skeleton:a,loading:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowingTeamsList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowingTeamsList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowingTeamsList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FfollowingTeamsList\u002FRESET"}},activityList:{list:[],cursor:f,hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FactivityList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FactivityList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FactivityList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FactivityList\u002FRESET"}},bookList:{list:[],cursor:f,skeleton:a,hasMore:a,loading:a,type:"wrote",actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FbookList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FbookList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FbookList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FbookList\u002FRESET"}},pinList:{list:[],hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FpinList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FpinList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FpinList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FpinList\u002FRESET"}},courseList:{list:[],hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FcourseList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FcourseList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FcourseList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FcourseList\u002FRESET"}},pinPraisedList:{list:[],cursor:f,hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FpinPraisedList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FpinPraisedList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FpinPraisedList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FpinPraisedList\u002FRESET"}},eventList:{list:[],cursor:f,hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FeventList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FeventList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FeventList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FeventList\u002FRESET"}},selfColumnList:{list:[],hasMore:a,skeleton:a,loading:a,cursor:f,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnList\u002FRESET"}},columnFollowedList:{list:[],hasMore:a,skeleton:a,loading:a,cursor:f,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnFollowedList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnFollowedList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnFollowedList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnFollowedList\u002FRESET",FILTER:"@\u002Fview\u002Fuser\u002FdetailList\u002FcolumnFollowedList\u002FFILTER"}},realtimes:{list:[],cursor:f,hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimes\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimes\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimes\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimes\u002FRESET",DELETE:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimes\u002FDELETE"}},realtimeliked:{list:[],cursor:f,hasMore:a,loading:a,skeleton:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimeliked\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimeliked\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimeliked\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimeliked\u002FRESET",DELETE:"@\u002Fview\u002Fuser\u002FdetailList\u002Frealtimeliked\u002FDELETE"}},robotList:{list:[],cursor:f,type:w,hasMore:a,skeleton:a,loading:a,actionType:{FETCH:"@\u002Fview\u002Fuser\u002FdetailList\u002FrobotList\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fuser\u002FdetailList\u002FrobotList\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fuser\u002FdetailList\u002FrobotList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fuser\u002FdetailList\u002FrobotList\u002FRESET"}}}},tag:{tag:{},actionType:{FETCH:"@\u002Fview\u002Ftag\u002FFETCH",FETCH_LIST:"@\u002Fview\u002Ftag\u002FFETCH_LIST",RESET:"@\u002Fview\u002Ftag\u002FRESET"},list:{list:[],cursor:f,loading:a,skeleton:a,hasMore:a,actionType:{UPDATE_STATE:"@\u002Fview\u002Ftag\u002Flist\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Ftag\u002Flist\u002FFETCH_MORE",FETCH:"@\u002Fview\u002Ftag\u002Flist\u002FFETCH",RESET:"@\u002Fview\u002Ftag\u002Flist\u002FRESET"}}},notification:{user:{actionType:{RESET:"@\u002Fview\u002Fnotification\u002Fuser\u002FRESET"},listState:{list:[],cursor:f,hasMore:a,isLoading:a,messageType:j,msgTotal:b,msgSubMap:{"1":b,"2":b,"3":b,"4":b,"7":b}},list:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Fnotification\u002Fuser\u002Flist\u002FUPDATE",FETCH:"@\u002Fview\u002Fnotification\u002Fuser\u002Flist\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Fnotification\u002Fuser\u002Flist\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Fnotification\u002Fuser\u002Flist\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fnotification\u002Fuser\u002Flist\u002FRESET"}}},system:{actionType:{RESET:"@\u002Fview\u002Fnotification\u002Fsystem\u002FRESET"},list:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Fnotification\u002Fsystem\u002Flist\u002FUPDATE",FETCH:"@\u002Fview\u002Fnotification\u002Fsystem\u002Flist\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Fnotification\u002Fsystem\u002Flist\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Fnotification\u002Fsystem\u002Flist\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fnotification\u002Fsystem\u002Flist\u002FRESET"}}}},column:{serverRenderList:a,column:{id:k},entry:{id:k,screenshot:n,liked:a,article_id:k,article_info:{article_id:k,user_id:x,category_id:"6809637773935378440",tag_ids:[7257794499869573000],visible_level:b,link_url:e,cover_image:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Ff5874bf342044e49a66d5f9a5e8d88bb~tplv-k3u1fbpfcp-jj-mark:0:0:0:0:q75.image#?w=800&h=500&s=83748&e=webp&b=23443d",is_gfw:b,title:y,brief_content:z,is_english:b,is_original:g,user_index:8.158906220151882,original_type:b,original_author:e,content:e,ctime:"1693578608",mtime:A,rtime:A,draft_id:B,view_count:C,collect_count:j,digg_count:j,comment_count:o,hot_index:166,is_hot:b,rank_index:.00193933,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:g,web_html_content:"\u003Cstyle\u003E.markdown-body{word-break:break-word;line-height:1.75;font-weight:400;font-size:16px;overflow-x:hidden;color:#252933}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{line-height:1.5;margin-top:35px;margin-bottom:10px;padding-bottom:5px}.markdown-body h1{font-size:24px;line-height:38px;margin-bottom:5px}.markdown-body h2{font-size:22px;line-height:34px;padding-bottom:12px;border-bottom:1px solid #ececec}.markdown-body h3{font-size:20px;line-height:28px}.markdown-body h4{font-size:18px;line-height:26px}.markdown-body h5{font-size:17px;line-height:24px}.markdown-body h6{font-size:16px;line-height:24px}.markdown-body p{line-height:inherit;margin-top:22px;margin-bottom:22px}.markdown-body img{max-width:100%}.markdown-body hr{border:none;border-top:1px solid #ddd;margin-top:32px;margin-bottom:32px}.markdown-body code{word-break:break-word;border-radius:2px;overflow-x:auto;background-color:#fff5f5;color:#ff502c;font-size:.87em;padding:.065em .4em}.markdown-body code,.markdown-body pre{font-family:Menlo,Monaco,Consolas,Courier New,monospace}.markdown-body pre{overflow:auto;position:relative;line-height:1.75}.markdown-body pre\u003Ecode{font-size:12px;padding:15px 12px;margin:0;word-break:normal;display:block;overflow-x:auto;color:#333;background:#f8f8f8}.markdown-body a{text-decoration:none;color:#0269c8;border-bottom:1px solid #d1e9ff}.markdown-body a:active,.markdown-body a:hover{color:#275b8c}.markdown-body table{display:inline-block!important;font-size:12px;width:auto;max-width:100%;overflow:auto;border:1px solid #f6f6f6}.markdown-body thead{background:#f6f6f6;color:#000;text-align:left}.markdown-body tr:nth-child(2n){background-color:#fcfcfc}.markdown-body td,.markdown-body th{padding:12px 7px;line-height:24px}.markdown-body td{min-width:120px}.markdown-body blockquote{color:#666;padding:1px 23px;margin:22px 0;border-left:4px solid #cbcbcb;background-color:#f8f8f8}.markdown-body blockquote:after{display:block;content:\"\"}.markdown-body blockquote\u003Ep{margin:10px 0}.markdown-body ol,.markdown-body ul{padding-left:28px}.markdown-body ol li,.markdown-body ul li{margin-bottom:0;list-style:inherit}.markdown-body ol li .task-list-item,.markdown-body ul li .task-list-item{list-style:none}.markdown-body ol li .task-list-item ol,.markdown-body ol li .task-list-item ul,.markdown-body ul li .task-list-item ol,.markdown-body ul li .task-list-item ul{margin-top:0}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:3px}.markdown-body ol li{padding-left:6px}.markdown-body .contains-task-list{padding-left:0}.markdown-body .task-list-item{list-style:none}@media (max-width:720px){.markdown-body h1{font-size:24px}.markdown-body h2{font-size:20px}.markdown-body h3{font-size:18px}}\u003C\u002Fstyle\u003E\u003Cstyle data-highlight data-highlight-key=\"juejin\"\u003E.markdown-body pre,.markdown-body pre\u003Ecode.hljs{color:#333;background:#f8f8f8}.hljs-comment,.hljs-quote{color:#998;font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#333;font-weight:700}.hljs-literal,.hljs-number,.hljs-tag .hljs-attr,.hljs-template-variable,.hljs-variable{color:teal}.hljs-doctag,.hljs-string{color:#d14}.hljs-section,.hljs-selector-id,.hljs-title{color:#900;font-weight:700}.hljs-subst{font-weight:400}.hljs-class .hljs-title,.hljs-type{color:#458;font-weight:700}.hljs-attribute,.hljs-name,.hljs-tag{color:navy;font-weight:400}.hljs-link,.hljs-regexp{color:#009926}.hljs-bullet,.hljs-symbol{color:#990073}.hljs-built_in,.hljs-builtin-name{color:#0086b3}.hljs-meta{color:#999;font-weight:700}.hljs-deletion{background:#fdd}.hljs-addition{background:#dfd}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}\u003C\u002Fstyle\u003E\u003Cp\u003E\u003Cstrong\u003E本文为稀土掘金技术社区首发签约文章，30天内禁止转载，30天后未获授权禁止转载，侵权必究！\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡模式已经无法满足超大模型进行训练的要求。因此，我们需要基于单机多卡、甚至是多机多卡进行分布式大模型的训练。\u003C\u002Fp\u003E\n\u003Cp\u003E而利用AI集群，使深度学习算法更好地从大量数据中高效地训练出性能优良的大模型是分布式机器学习的首要目标。为了实现该目标，一般需要根据硬件资源与数据\u002F模型规模的匹配情况，考虑对计算任务、训练数据和模型进行划分，从而进行分布式存储和分布式训练。因此，分布式训练相关技术值得我们进行深入分析其背后的机理。\u003C\u002Fp\u003E\n\u003Cp\u003E下面主要对大模型进行分布式训练的并行技术进行讲解，本系列大体分八篇文章进行讲解。\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Flink.juejin.cn?target=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F598714869\" target=\"_blank\" title=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F598714869\" ref=\"nofollow noopener noreferrer\"\u003E大模型分布式训练并行技术（一）-概述\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Flink.juejin.cn?target=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F650002268\" target=\"_blank\" title=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F650002268\" ref=\"nofollow noopener noreferrer\"\u003E大模型分布式训练并行技术（二）-数据并行\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fjuejin.cn\u002Fpost\u002F7262274383287484476\" target=\"_blank\" title=\"https:\u002F\u002Fjuejin.cn\u002Fpost\u002F7262274383287484476\"\u003E大模型分布式训练并行技术（三）-流水线并行\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fjuejin.cn\u002Fpost\u002F7269698032655728640\" target=\"_blank\" title=\"https:\u002F\u002Fjuejin.cn\u002Fpost\u002F7269698032655728640\"\u003E大模型分布式训练并行技术（四）-张量并行\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E大模型分布式训练并行技术（五）-序列并行\u003C\u002Fli\u003E\n\u003Cli\u003E大模型分布式训练并行技术（六）-多维混合并行\u003C\u002Fli\u003E\n\u003Cli\u003E大模型分布式训练并行技术（七）-自动并行\u003C\u002Fli\u003E\n\u003Cli\u003E大模型分布式训练并行技术（八）-MOE并行\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E本文为分布式训练并行技术的第五篇：序列并行。目前，有两篇关于序列并行的文章：\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E第一篇是 Colossal-AI 发表的论文：Sequence Parallelism: Long Sequence Training from System Perspective\u003C\u002Fli\u003E\n\u003Cli\u003E第二篇是 Megatron-LM 发表的论文：Reducing Activation Recomputation in Large Transformer Models\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E虽然两者都叫序列并行（Sequence Parallelism），但是实际上解决的问题、方法都不一样。前者主要是解决模型的输入长度(sequence length)限制，而后者是主要是减少模型显存的。下面将一一讲对其进行解。\u003C\u002Fp\u003E\n\u003Ch2 data-id=\"heading-0\"\u003E序列并行（Colossal-AI）\u003C\u002Fh2\u003E\n\u003Cp\u003EColossal-AI 序列并行诞生的背景是 self-attention 的内存需求是输入长度（sequence length）的2次方。其复杂度为 \u003Cspan class=\"math math-inline\"\u003E\u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmi\u003EO\u003C\u002Fmi\u003E\u003Cmo stretchy=\"false\"\u003E(\u003C\u002Fmo\u003E\u003Cmsup\u003E\u003Cmi\u003En\u003C\u002Fmi\u003E\u003Cmn\u003E2\u003C\u002Fmn\u003E\u003C\u002Fmsup\u003E\u003Cmo stretchy=\"false\"\u003E)\u003C\u002Fmo\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003EO(n^2)\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003EO\u003C\u002Fspan\u003E\u003Cspan class=\"mopen\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"mord\"\u003E\u003Cspan class=\"mord mathnormal\"\u003En\u003C\u002Fspan\u003E\u003Cspan class=\"msupsub\"\u003E\u003Cspan class=\"vlist-t\"\u003E\u003Cspan class=\"vlist-r\"\u003E\u003Cspan class=\"vlist\" style=\"height:0.8141em;\"\u003E\u003Cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003E\u003Cspan class=\"pstrut\" style=\"height:2.7em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"sizing reset-size6 size3 mtight\"\u003E\u003Cspan class=\"mord mtight\"\u003E2\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mclose\"\u003E)\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E，其中，n 是序列长度。换言之，长序列数据将增加中间activation内存使用量，从而限制设备的训练能力。\u003C\u002Fp\u003E\n\u003Cp\u003E而现有的工作侧重于从算法的角度降低时间和空间复杂度。因此，作者提出了序列并行，这是一种内存高效的并行方法，可以帮助我们打破输入序列长度限制，并在 GPU 上有效地训练更长的序列；同时，该方法与大多数现有的并行技术兼容（例如：数据并行、流水线并行和张量并行）。\u003C\u002Fp\u003E\n\u003Cp\u003E更重要的是，我们不再需要单个设备来保存整个序列。 即在稀疏注意力的情况下，我们的序列并行使我们能够训练具有无限长序列的 Transformer。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp1-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Fdd8f31a28f504891af7d0379064f20ac~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E具体来说，我们将输入序列分割成多个块，并将每个块输入到其相应的设备（即 GPU）中。为了计算注意力输出，我们将环状通信与自注意力计算相结合，并提出了环自注意力（RSA）如下图所示。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp9-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Ff8d4b9f9a76248879a6c19b4487802c4~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E实验表明，当按批量大小和序列长度进行缩放时，序列并行表现良好。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp1-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Fa5dbc208b8b44896b2a6dd571cbae8cc~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp9-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Fdb70e40767e74a1ca61d8c5710f4fd18~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E当扩展到 64 个 NVIDIA P100 GPU 时，与张量并相比，该法分别实现了 13.7 倍和 3.0 倍的最大批量大小和序列长度。\u003C\u002Fp\u003E\n\u003Cp\u003E通过稀疏注意力，序列可以处理具有超过 114K 个 Token 的序列，这比现有的在单个设备上保存整个序列的稀疏注意力运行长度超过 27 倍。\u003C\u002Fp\u003E\n\u003Cp\u003E除此之外，与张量并行和流水线并行不同，序列并行不受超参数（例如：\n注意力头数、层数）限制。 因此，只要序列长度能被序列并行大小整除，我们的序列并行就可以使用。\u003C\u002Fp\u003E\n\u003Ch2 data-id=\"heading-1\"\u003E序列并行（Megatron-LM）\u003C\u002Fh2\u003E\n\u003Cp\u003EMegatron-LM 的初衷是考虑通过其他方式分摊张量并行中无法分摊的显存，因此提出了序列并行的方法。\u003C\u002Fp\u003E\n\u003Cp\u003E虽然 Megatron-LM 引用了 Colossal-AI 的序列并行的这篇文章，但是这两者其实并不是一个东西。\u003C\u002Fp\u003E\n\u003Cp\u003EMegatron-LM 只是借用了 Colossal-AI 把 Sequence 这个维度进行平均划分的思想。在 张量的基础上，将 Transformer 层中的 LayerNorm 以及 Dropout 的输入按输入长度（Sequence Length）维度进行了切分，使得各个设备上面只需要做一部分的 Dropout 和 LayerNorm 即可。\u003C\u002Fp\u003E\n\u003Cp\u003E这样做的好处有：\u003C\u002Fp\u003E\n\u003Col\u003E\n\u003Cli\u003ELayerNorm 和 Dropout 的计算被平摊到了各个设备上，减少了计算资源的浪费；\u003C\u002Fli\u003E\n\u003Cli\u003ELayerNorm 和 Dropout 所产生的激活值也被平摊到了各个设备上，进一步降低了显存开销。\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Cp\u003E在 Megatron-LM 序列并行的这篇论文中，首先分析了 Transformer 模型运行时的显存占用情况。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Fc3bfb065502647b4a7428c8d31b29886~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E假设输入长度为 s ，batch size为 b ，hidden dim为 h ，attention head数量为 a ，则每一层 Transformer（上图的灰色区域）的显存占用：\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Fac973d75e03d411dafe809a337ba923a~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E当我们开启了张量并行之后，上述Transformer层中的部分模块的显存可以被分摊到不同的设备之间。如下图所示，不能被分摊的部分主要是两个 LayerNorm 块的输入和输出： 4bsh ；两个 dropout mask 块：2bsh ；一共是 10bsh。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp1-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F10fb4f441b4642ffa815168ed2132921~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E假设张量并行大小为t，因此，每个设备每一层 Transformer 的显存占用为：\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F746ec1f345c14a119b33e7e4dc1608da~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E下面开启张量并行以及序列并行，Transformer 层中的 LayerNorm 和 Dropout 块也会被切分，对 Tensor 在 Sequence 维度进行切分，切分数量等于张量并行大小。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp6-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Fd975ec75f96c492e8f73ae4a41c7d1a2~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E每个设备每一层 Transformer 的显存占用为：\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp1-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F34116a015e794a7eaa61d7eea16c2a52~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E当然，做了额外的切分就会带来通信方式的改变。\u003C\u002Fp\u003E\n\u003Cp\u003ETransformer 层的张量并行通信是由正向传播两个All-Reduce以及反向传播两个All-Reduce组成。\u003C\u002Fp\u003E\n\u003Cp\u003E而序列并行由于对 Sequence 维度进行了划分，All-Reduce在这里已经不合适了。\u003C\u002Fp\u003E\n\u003Cp\u003E为了收集在各个设备上进行序列并行所产生的结果，需要插入All-Gather算子；而为了使得张量并行所产生的结果可以传入序列并行层，需要插入Reduce-Scatter算子。\u003C\u002Fp\u003E\n\u003Cp\u003E在下图中， \u003Cspan class=\"math math-inline\"\u003E\u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmi\u003Eg\u003C\u002Fmi\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003Eg\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003Eg\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E 所代表的就是前向传播的 All-Gather，反向传播的 Reduce-Scatter，\u003Cspan class=\"math math-inline\"\u003E\u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmover accent=\"true\"\u003E\u003Cmi\u003Eg\u003C\u002Fmi\u003E\u003Cmo stretchy=\"true\"\u003E‾\u003C\u002Fmo\u003E\u003C\u002Fmover\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003E\\overline{g}\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.825em;vertical-align:-0.1944em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord overline\"\u003E\u003Cspan class=\"vlist-t vlist-t2\"\u003E\u003Cspan class=\"vlist-r\"\u003E\u003Cspan class=\"vlist\" style=\"height:0.6306em;\"\u003E\u003Cspan style=\"top:-3em;\"\u003E\u003Cspan class=\"pstrut\" style=\"height:3em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord\"\u003E\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003Eg\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan style=\"top:-3.5506em;\"\u003E\u003Cspan class=\"pstrut\" style=\"height:3em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"overline-line\" style=\"border-bottom-width:0.04em;\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"vlist-s\"\u003E​\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"vlist-r\"\u003E\u003Cspan class=\"vlist\" style=\"height:0.1944em;\"\u003E\u003Cspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E 则是相反的操作。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Fa44912c47ef24fd681ed0ca6cd1ac38b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E因此，我们可以清楚地看到，在 Megatron-LM 同时开启序列并行和模型并行时，每一个 Transformer 层完成一次前向传播和反向传播一共有 4 个 All-Gather 和 4 个 Reduce-Scatter 算子。乍一看，通信的操作比 Megatron-LM 仅开启张量并行多，但其实不然。因为，一个All-Reduce就相当于一个 Reduce-Scatter 和一个 All-Gather ，所以他们的总通信量是一样的。\u003C\u002Fp\u003E\n\u003Cp\u003E通过添加序列并行并没有增加额外的通信开销，反而在后向传播代码的实现上，还把 Reduce-Scatter 和权重梯度的计算做了重叠，进一步减少了通信所占用的时间，使得提高设备的FLOPs Utilization成为了可能。\u003C\u002Fp\u003E\n\u003Cp\u003E通过对Transformer层中所有Activation的消耗进行计算，发现在Transformer层里有一些操作是产生的激活值大，但计算量小。因此，就考虑干掉这一部分的激活值，通过选择性的进行激活重新计算（Selective Activation Recomputation）来进一步降低显存。与此同时，其他的激活值就通通保存，以节省重计算量。\u003C\u002Fp\u003E\n\u003Cp\u003E通过对激活值的占比分析，序列并行降低了4成左右的激活值开销。选择性激活重新计算（selective activation recompute）也降低了4成左右的激活值开销。当两个特性都打开的时候，总共可以降低8成左右的激活值开销，尽管比全部激活值重计算的结果要稍高，但是在吞吐率上的提升还是非常的明显的。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F2eaa429312ed4d4fa658536bc26b102e~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp\" alt=\"image.png\" loading=\"lazy\"\u003E\u003C\u002Fp\u003E\n\u003Ch2 data-id=\"heading-2\"\u003EPytorch 中的序列并行\u003C\u002Fh2\u003E\n\u003Cp\u003E上一篇张量并行的文章中提到 Pytorch 从 2.0.0 开始已经开始支持张量并行了。参考 Megatron-LM 的序列并行，目前在 Pytorch 中，也已经支持序列并行了，不过还没有 Release，具体示例如下所示：\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode class=\"hljs language-python\" lang=\"python\"\u003E\u003Cspan class=\"hljs-comment\"\u003E# 通过设备网格根据给定的 world_size 创建分片计划\u003C\u002Fspan\u003E\ndevice_mesh = DeviceMesh(\u003Cspan class=\"hljs-string\"\u003E\"cuda\"\u003C\u002Fspan\u003E, torch.arange(\u003Cspan class=\"hljs-number\"\u003E0\u003C\u002Fspan\u003E, args.world_size))\n\n\u003Cspan class=\"hljs-comment\"\u003E# 创建模型并移动到GPU\u003C\u002Fspan\u003E\nmodel = ToyModel().cuda(rank)\n\n\u003Cspan class=\"hljs-comment\"\u003E# 为并行化模块创建优化器\u003C\u002Fspan\u003E\nLR = \u003Cspan class=\"hljs-number\"\u003E0.25\u003C\u002Fspan\u003E\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\n\n\u003Cspan class=\"hljs-comment\"\u003E# 根据给定的并行风格并行化模块，这里指定为序列并行\u003C\u002Fspan\u003E\nmodel = parallelize_module(model, device_mesh, SequenceParallel())\n\n\u003Cspan class=\"hljs-comment\"\u003E# 对分片模块执行多次前向\u002F后向传播和优化器对参数进行更新。\u003C\u002Fspan\u003E\n\u003Cspan class=\"hljs-keyword\"\u003Efor\u003C\u002Fspan\u003E _ \u003Cspan class=\"hljs-keyword\"\u003Ein\u003C\u002Fspan\u003E \u003Cspan class=\"hljs-built_in\"\u003Erange\u003C\u002Fspan\u003E(args.iter_nums):\n    \u003Cspan class=\"hljs-comment\"\u003E# 对于 SP，所有rank的输入可以不同。\u003C\u002Fspan\u003E\n    inp = torch.rand(\u003Cspan class=\"hljs-number\"\u003E20\u003C\u002Fspan\u003E, \u003Cspan class=\"hljs-number\"\u003E10\u003C\u002Fspan\u003E).cuda(rank)\n    output = model(inp)\n    output.\u003Cspan class=\"hljs-built_in\"\u003Esum\u003C\u002Fspan\u003E().backward()\n    optimizer.step()\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch2 data-id=\"heading-3\"\u003E结语\u003C\u002Fh2\u003E\n\u003Cp\u003E总的来说，Colossal-AI 的序列并行是为了打破单设备上序列长度的限制。而 Megatron-LM 的序列并行是在显存上面下了功夫，可以用更少的设备去运行大模型。除此之外，从文章细节里面可以看到，部分的计算的冗余被消除了，且重叠了一部分的通信，使得设备可以花更多的时间用于计算上面。虽然，Colossal-AI 和 Megatron-LM 都有序列并行，但是两者解决的问题、方法都不一样。除此之外，在Pytorch中，也已经支持序列并行了。\u003C\u002Fp\u003E\n\u003Cp\u003E码字不易，如果觉得我的文章能够能够给您带来帮助，期待您的点赞收藏加关注~~\u003C\u002Fp\u003E",meta_info:"{\"plugins\":[6,3,5]}",catalog:"[{\"title\":\"序列并行（Colossal-AI）\",\"hash\":\"#heading-0\",\"deep\":1,\"children\":[],\"visible\":true},{\"title\":\"序列并行（Megatron-LM）\",\"hash\":\"#heading-1\",\"deep\":1,\"children\":[],\"visible\":true},{\"title\":\"Pytorch 中的序列并行\",\"hash\":\"#heading-2\",\"deep\":1,\"children\":[],\"visible\":true},{\"title\":\"结语\",\"hash\":\"#heading-3\",\"deep\":1,\"children\":[],\"visible\":true}]",homepage_top_time:l,homepage_top_status:b,content_count:2533,read_time:"8分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:t,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:h,follower_count:477,post_article_count:325,digg_article_count:17,got_digg_count:457,got_view_count:426334,post_shortmsg_count:9,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:E,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:d,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:3642056016410728,jpower:E,jscore:1976,jpower_level:t,jscore_level:t,jscore_title:"先锋掘友",author_achievement_list:[g],vip_level:b,vip_title:e,jscore_next_level_score:2000,jscore_this_level_mini_score:500,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"7257794499869573175",tag_id:"7257794499869573175",tag_name:"LLM",color:e,icon:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F461a12434205464287418fa250495073~tplv-k3u1fbpfcp-watermark.image?",back_ground:e,show_navi:b,ctime:1689836965,mtime:1716889140,id_type:9,tag_alias:"大型语言模型,Large Language Model",post_article_count:2376,concern_user_count:3222,title:"LLM",tagId:"7257794499869573175",articleCount:2376,subscribersCount:3222,createdAt:c,updatedAt:c}],user_interact:{id:7273680143658287000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{org_info:c,is_followed:a},req_id:"20240528193804AA5630F1869E4F58D1FD",status:{push_status:b},theme_list:[{theme:{theme_id:"7215101111321395200",name:"人工智能创作者签约季",cover:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F8afec2105c7644bb9f432390d8182b76~tplv-k3u1fbpfcp-no-mark:0:0:0:0.image?",brief:"招募深耕人工智能领域的图文创作者进行签约，成功签约后可以获得掘金签约作者认证、现金稿费以及更多其他支持！",is_lottery:a,is_rec:a,rec_rank:b,topic_ids:[],hot:3156086,view_cnt:4962,user_cnt:2098,status:b,ctime:l,mtime:1711079264,lottery_begin_time:l,lottery_end_time:l,theme_type:g,last_hot:9647,has_expiration:a,valid_begin_time:l,valid_end_time:l,expired:b}}],title:y,user:F,viewCount:n,commentsCount:o,isEvent:n,abstract:z,latestCommentAt:c,createdAt:new Date(1693578608000),updatedAt:c,isTopicEvent:a,likedCount:j,likeCount:j,content:e,originalUrl:e,type:"post",collected:a,viewsCount:C,username:D,viewerHasLiked:a,draftId:B,collectionCount:j,isCache:d},entryView:{},author:F,adEntryList:[],relatedEntryList:[],selectedList:[],linkVotingList:[],userAnnuals:[],columnList:[],hitArticleCache:d,authorCard:{},relatedLoaded:a,dynamicDataReady:a,followAuthorPopupTime:b,followAuthorPopupType:b,authorBlockVisible:b,compVisible:{},version:g,actionType:{FETCH:"view\u002Fcolumn\u002FFETCH",FETCH_RELATED:"view\u002Fcolumn\u002FFETCH_RELATED",FETCH_RECOMMEND:"view\u002Fcolumn\u002FFETCH_RECOMMEND",FETCH_SELECTED:"view\u002Fcolumn\u002FFETCH_SELECTED",FETCH_ADDITIONAL:"view\u002Fcolumn\u002FFETCH_ADDITIONAL",FETCH_SIDEBAR_ADENTRY:"view\u002Fcolumn\u002FFETCH_SIDEBAR_ADENTRY",FETCH_AUTHOR_EXTRA:"view\u002Fcolumn\u002FFETCH_AUTHOR_EXTRA",MD_FALLBACK_RENDER:"view\u002Fcolumn\u002FMD_FALLBACK_RENDER",RESET:"view\u002Fcolumn\u002FRESET"},recommendedArticleList:{list:[{id:"7300499502758494217",screenshot:n,liked:a,article_id:"7300499502758494217",article_info:{article_id:"7300499502758494217",user_id:x,category_id:"6809637773935378440",tag_ids:[7257794499869573000],visible_level:b,link_url:e,cover_image:e,is_gfw:b,title:"大模型参数高效微调技术原理综述（六）-MAM Adapter、UniPELT",brief_content:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",is_english:b,is_original:g,user_index:8.505620140850969,original_type:b,original_author:e,content:e,ctime:"1699792571",mtime:"1699856379",rtime:"1699856379",draft_id:"7242623686900809788",view_count:602,collect_count:g,digg_count:b,comment_count:b,hot_index:30,is_hot:b,rank_index:.00040574,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:g,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:1788,read_time:"6分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"7257794499869573175",tag_id:"7257794499869573175",tag_name:"LLM",color:e,icon:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F461a12434205464287418fa250495073~tplv-k3u1fbpfcp-watermark.image?",back_ground:e,show_navi:b,ctime:1689836965,mtime:1724156391,id_type:9,tag_alias:"大型语言模型,Large Language Model",post_article_count:2922,concern_user_count:4454,title:"LLM",tagId:"7257794499869573175",articleCount:2922,subscribersCount:4454,createdAt:c,updatedAt:c}],user_interact:{id:7300499502758494000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型参数高效微调技术原理综述（六）-MAM Adapter、UniPELT",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:b,isEvent:n,abstract:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",latestCommentAt:c,createdAt:new Date(1699792571000),updatedAt:c,isTopicEvent:a,likedCount:b,likeCount:b,content:e,originalUrl:e,type:"post",collected:a,viewsCount:602,username:D,viewerHasLiked:a,draftId:"7242623686900809788",collectionCount:g},{id:"7280861248421019659",screenshot:n,liked:a,article_id:"7280861248421019659",article_info:{article_id:"7280861248421019659",user_id:x,category_id:"6809637773935378440",tag_ids:[7257794499869573000],visible_level:b,link_url:e,cover_image:e,is_gfw:b,title:"大模型分布式训练并行技术（七）-自动并行",brief_content:z,is_english:b,is_original:g,user_index:8.158906220151882,original_type:b,original_author:e,content:e,ctime:"1695271748",mtime:"1697015913",rtime:"1695366485",draft_id:"7261962730985340986",view_count:3243,collect_count:15,digg_count:15,comment_count:t,hot_index:182,is_hot:b,rank_index:.00160488,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:j,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:6063,read_time:"20分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"7257794499869573175",tag_id:"7257794499869573175",tag_name:"LLM",color:e,icon:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F461a12434205464287418fa250495073~tplv-k3u1fbpfcp-watermark.image?",back_ground:e,show_navi:b,ctime:1689836965,mtime:1724156391,id_type:9,tag_alias:"大型语言模型,Large Language Model",post_article_count:2922,concern_user_count:4454,title:"LLM",tagId:"7257794499869573175",articleCount:2922,subscribersCount:4454,createdAt:c,updatedAt:c}],user_interact:{id:7280861248421020000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型分布式训练并行技术（七）-自动并行",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:t,isEvent:n,abstract:z,latestCommentAt:c,createdAt:new Date(1695271748000),updatedAt:c,isTopicEvent:a,likedCount:15,likeCount:15,content:e,originalUrl:e,type:"post",collected:a,viewsCount:3243,username:D,viewerHasLiked:a,draftId:"7261962730985340986",collectionCount:15},{id:"7242217556623179833",screenshot:n,liked:a,article_id:"7242217556623179833",article_info:{article_id:"7242217556623179833",user_id:x,category_id:"6809637773935378440",tag_ids:[6809640642101117000],visible_level:b,link_url:e,cover_image:e,is_gfw:b,title:"大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning",brief_content:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",is_english:b,is_original:g,user_index:7.966120018545208,original_type:b,original_author:e,content:e,ctime:"1686218857",mtime:"1689908285",rtime:"1686292816",draft_id:"7241875961130188855",view_count:2017,collect_count:4,digg_count:t,comment_count:g,hot_index:106,is_hot:b,rank_index:.00067322,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:o,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:2273,read_time:"8分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"6809640642101116936",tag_id:"6809640642101116936",tag_name:"人工智能",color:"#2e6cff",icon:"https:\u002F\u002Fp1-jj.byteimg.com\u002Ftos-cn-i-t2oaga2asx\u002Fleancloud-assets\u002F9b525117507d7a76c4ac.png~tplv-t2oaga2asx-image.image",back_ground:e,show_navi:g,ctime:1472072600,mtime:1724158710,id_type:9,tag_alias:e,post_article_count:132374,concern_user_count:257272,title:"人工智能",tagId:"6809640642101116936",articleCount:132374,subscribersCount:257272,createdAt:c,updatedAt:c}],user_interact:{id:7242217556623180000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:g,isEvent:n,abstract:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",latestCommentAt:c,createdAt:new Date(1686218857000),updatedAt:c,isTopicEvent:a,likedCount:t,likeCount:t,content:e,originalUrl:e,type:"post",collected:a,viewsCount:2017,username:D,viewerHasLiked:a,draftId:"7241875961130188855",collectionCount:4},{id:"7242290406636781626",screenshot:n,liked:a,article_id:"7242290406636781626",article_info:{article_id:"7242290406636781626",user_id:x,category_id:"6809637773935378440",tag_ids:[6809640642101117000],visible_level:b,link_url:e,cover_image:e,is_gfw:b,title:"大模型参数高效微调技术原理综述（三）-P-Tuning、P-Tuning v2",brief_content:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",is_english:b,is_original:g,user_index:7.956830728985743,original_type:b,original_author:e,content:e,ctime:"1686239069",mtime:"1689922292",rtime:"1686292877",draft_id:"7242247549511794744",view_count:5394,collect_count:6,digg_count:o,comment_count:b,hot_index:271,is_hot:b,rank_index:.00164895,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:t,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:2410,read_time:"8分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"6809640642101116936",tag_id:"6809640642101116936",tag_name:"人工智能",color:"#2e6cff",icon:"https:\u002F\u002Fp1-jj.byteimg.com\u002Ftos-cn-i-t2oaga2asx\u002Fleancloud-assets\u002F9b525117507d7a76c4ac.png~tplv-t2oaga2asx-image.image",back_ground:e,show_navi:g,ctime:1472072600,mtime:1724158710,id_type:9,tag_alias:e,post_article_count:132374,concern_user_count:257272,title:"人工智能",tagId:"6809640642101116936",articleCount:132374,subscribersCount:257272,createdAt:c,updatedAt:c}],user_interact:{id:7242290406636782000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型参数高效微调技术原理综述（三）-P-Tuning、P-Tuning v2",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:b,isEvent:n,abstract:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",latestCommentAt:c,createdAt:new Date(1686239069000),updatedAt:c,isTopicEvent:a,likedCount:o,likeCount:o,content:e,originalUrl:e,type:"post",collected:a,viewsCount:5394,username:D,viewerHasLiked:a,draftId:"7242247549511794744",collectionCount:6},{id:"7289661052806594618",screenshot:n,liked:a,article_id:"7289661052806594618",article_info:{article_id:"7289661052806594618",user_id:x,category_id:"6809637773935378440",tag_ids:[7257794499869573000],visible_level:b,link_url:e,cover_image:e,is_gfw:b,title:"大模型分布式训练并行技术（八）-MOE并行",brief_content:"近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡模式已经无法满足超大模型进行训练的要求。因此，我们需要基于单机多卡、甚至是多机多卡进行分布式",is_english:b,is_original:g,user_index:8.158906220151882,original_type:b,original_author:e,content:e,ctime:"1697260306",mtime:"1697338779",rtime:"1697338779",draft_id:"7261932861682630711",view_count:3432,collect_count:6,digg_count:j,comment_count:b,hot_index:174,is_hot:b,rank_index:.0016862,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:g,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:2844,read_time:"9分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"7257794499869573175",tag_id:"7257794499869573175",tag_name:"LLM",color:e,icon:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F461a12434205464287418fa250495073~tplv-k3u1fbpfcp-watermark.image?",back_ground:e,show_navi:b,ctime:1689836965,mtime:1724156391,id_type:9,tag_alias:"大型语言模型,Large Language Model",post_article_count:2922,concern_user_count:4454,title:"LLM",tagId:"7257794499869573175",articleCount:2922,subscribersCount:4454,createdAt:c,updatedAt:c}],user_interact:{id:7289661052806595000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型分布式训练并行技术（八）-MOE并行",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:b,isEvent:n,abstract:"近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡模式已经无法满足超大模型进行训练的要求。因此，我们需要基于单机多卡、甚至是多机多卡进行分布式",latestCommentAt:c,createdAt:new Date(1697260306000),updatedAt:c,isTopicEvent:a,likedCount:j,likeCount:j,content:e,originalUrl:e,type:"post",collected:a,viewsCount:3432,username:D,viewerHasLiked:a,draftId:"7261932861682630711",collectionCount:6},{id:"7266044346527957007",screenshot:n,liked:a,article_id:"7266044346527957007",article_info:{article_id:"7266044346527957007",user_id:x,category_id:"6809637773935378440",tag_ids:[7257794499869573000],visible_level:b,link_url:e,cover_image:e,is_gfw:b,title:"大模型参数高效微调技术实战（六）-IA3",brief_content:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",is_english:b,is_original:g,user_index:8.158906220151882,original_type:b,original_author:e,content:e,ctime:"1691813160",mtime:"1696038870",rtime:"1691824687",draft_id:"7258191640564351037",view_count:888,collect_count:o,digg_count:4,comment_count:b,hot_index:48,is_hot:b,rank_index:.00040739,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:j,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:2053,read_time:"7分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"7257794499869573175",tag_id:"7257794499869573175",tag_name:"LLM",color:e,icon:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F461a12434205464287418fa250495073~tplv-k3u1fbpfcp-watermark.image?",back_ground:e,show_navi:b,ctime:1689836965,mtime:1724156391,id_type:9,tag_alias:"大型语言模型,Large Language Model",post_article_count:2922,concern_user_count:4454,title:"LLM",tagId:"7257794499869573175",articleCount:2922,subscribersCount:4454,createdAt:c,updatedAt:c}],user_interact:{id:7266044346527957000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型参数高效微调技术实战（六）-IA3",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:b,isEvent:n,abstract:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",latestCommentAt:c,createdAt:new Date(1691813160000),updatedAt:c,isTopicEvent:a,likedCount:4,likeCount:4,content:e,originalUrl:e,type:"post",collected:a,viewsCount:888,username:D,viewerHasLiked:a,draftId:"7258191640564351037",collectionCount:o},{id:"7242677017057755191",screenshot:n,liked:a,article_id:"7242677017057755191",article_info:{article_id:"7242677017057755191",user_id:x,category_id:"6809637773935378440",tag_ids:[6809640642101117000],visible_level:b,link_url:e,cover_image:e,is_gfw:b,title:"大模型参数高效微调技术原理综述（四）-Adapter Tuning及其变体",brief_content:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",is_english:b,is_original:g,user_index:7.982668800496526,original_type:b,original_author:e,content:e,ctime:"1686357208",mtime:"1686558673",rtime:"1686558673",draft_id:"7240751116702040101",view_count:2462,collect_count:t,digg_count:j,comment_count:b,hot_index:126,is_hot:b,rank_index:.00079896,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:o,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:2685,read_time:"9分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"6809640642101116936",tag_id:"6809640642101116936",tag_name:"人工智能",color:"#2e6cff",icon:"https:\u002F\u002Fp1-jj.byteimg.com\u002Ftos-cn-i-t2oaga2asx\u002Fleancloud-assets\u002F9b525117507d7a76c4ac.png~tplv-t2oaga2asx-image.image",back_ground:e,show_navi:g,ctime:1472072600,mtime:1724158710,id_type:9,tag_alias:e,post_article_count:132374,concern_user_count:257272,title:"人工智能",tagId:"6809640642101116936",articleCount:132374,subscribersCount:257272,createdAt:c,updatedAt:c}],user_interact:{id:7242677017057755000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型参数高效微调技术原理综述（四）-Adapter Tuning及其变体",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:b,isEvent:n,abstract:"随着，ChatGPT 迅速爆火，引发了大模型的时代变革。然而对于普通大众来说，进行大模型的预训练或者全量微调遥不可及。由此，催生了各种参数高效微调技术，让科研人员或者普通开发者有机会尝试微调大模型。 ",latestCommentAt:c,createdAt:new Date(1686357208000),updatedAt:c,isTopicEvent:a,likedCount:j,likeCount:j,content:e,originalUrl:e,type:"post",collected:a,viewsCount:2462,username:D,viewerHasLiked:a,draftId:"7240751116702040101",collectionCount:t},{id:"7254001262646738981",screenshot:n,liked:a,article_id:"7254001262646738981",article_info:{article_id:"7254001262646738981",user_id:x,category_id:"6809637773935378440",tag_ids:[6809640642101117000],visible_level:b,link_url:e,cover_image:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002Ffbddf28b05f3465894ed796df67bc1b2~tplv-k3u1fbpfcp-watermark.image?",is_gfw:b,title:"大模型分布式训练并行技术（二）-数据并行",brief_content:"近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡模式已经无法满足超大模型进行训练的要求。因此，我们需要基于单机多卡、甚至是多机多卡进行分布式",is_english:b,is_original:g,user_index:8.123094746364249,original_type:b,original_author:e,content:e,ctime:"1688965671",mtime:"1691925164",rtime:"1688973497",draft_id:"7246924217680412732",view_count:6531,collect_count:13,digg_count:10,comment_count:j,hot_index:339,is_hot:b,rank_index:.0022581,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:j,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:5563,read_time:"19分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"6809640642101116936",tag_id:"6809640642101116936",tag_name:"人工智能",color:"#2e6cff",icon:"https:\u002F\u002Fp1-jj.byteimg.com\u002Ftos-cn-i-t2oaga2asx\u002Fleancloud-assets\u002F9b525117507d7a76c4ac.png~tplv-t2oaga2asx-image.image",back_ground:e,show_navi:g,ctime:1472072600,mtime:1724158710,id_type:9,tag_alias:e,post_article_count:132374,concern_user_count:257272,title:"人工智能",tagId:"6809640642101116936",articleCount:132374,subscribersCount:257272,createdAt:c,updatedAt:c}],user_interact:{id:7254001262646739000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型分布式训练并行技术（二）-数据并行",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:j,isEvent:n,abstract:"近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡模式已经无法满足超大模型进行训练的要求。因此，我们需要基于单机多卡、甚至是多机多卡进行分布式",latestCommentAt:c,createdAt:new Date(1688965671000),updatedAt:c,isTopicEvent:a,likedCount:10,likeCount:10,content:e,originalUrl:e,type:"post",collected:a,viewsCount:6531,username:D,viewerHasLiked:a,draftId:"7246924217680412732",collectionCount:13},{id:"7277799192966578176",screenshot:n,liked:a,article_id:"7277799192966578176",article_info:{article_id:"7277799192966578176",user_id:x,category_id:"6809637773935378440",tag_ids:[7257794499869573000],visible_level:b,link_url:e,cover_image:e,is_gfw:b,title:"大模型分布式训练并行技术（六）-多维混合并行",brief_content:z,is_english:b,is_original:g,user_index:8.158906220151882,original_type:b,original_author:e,content:e,ctime:"1694528303",mtime:"1695095335",rtime:"1695095335",draft_id:"7260859104951468087",view_count:5161,collect_count:10,digg_count:10,comment_count:o,hot_index:270,is_hot:b,rank_index:.00231817,status:o,verify_status:g,audit_status:o,mark_content:e,display_count:b,is_markdown:g,app_html_content:e,version:g,web_html_content:c,meta_info:c,catalog:c,homepage_top_time:l,homepage_top_status:b,content_count:3147,read_time:"10分钟"},author_user_info:{user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",level:b,description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b}},category:{category_id:"6809637773935378440",category_name:"人工智能",category_url:"ai",rank:t,back_ground:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002Ff7cecf8806e8621ef35e.jpg",icon:"https:\u002F\u002Flc-mhke0kuv.cn-n1.lcfile.com\u002F9b525117507d7a76c4ac.png",ctime:1500876664,mtime:1500876667,show_type:j,item_type:o,promote_tag_cap:4,promote_priority:t,id:"6809637773935378440",name:"人工智能",title:"人工智能",alias:"ai"},tags:[{entriesCount:n,subscribed:a,id:"7257794499869573175",tag_id:"7257794499869573175",tag_name:"LLM",color:e,icon:"https:\u002F\u002Fp3-juejin.byteimg.com\u002Ftos-cn-i-k3u1fbpfcp\u002F461a12434205464287418fa250495073~tplv-k3u1fbpfcp-watermark.image?",back_ground:e,show_navi:b,ctime:1689836965,mtime:1724156391,id_type:9,tag_alias:"大型语言模型,Large Language Model",post_article_count:2922,concern_user_count:4454,title:"LLM",tagId:"7257794499869573175",articleCount:2922,subscribersCount:4454,createdAt:c,updatedAt:c}],user_interact:{id:7277799192966578000,omitempty:o,user_id:b,is_digg:a,is_follow:a,is_collect:a,collect_set_count:b},org:{is_followed:a},req_id:"20240820214833054642A1C3CD6E078989",status:{push_status:b},theme_list:[],extra:{extra:e},title:"大模型分布式训练并行技术（六）-多维混合并行",user:{id:x,self_description:n,followed:a,viewerIsFollowing:n,community:n,subscribedTagCount:b,wroteBookCount:b,boughtBookCount:b,isBindedPhone:a,level:b,user_id:x,user_name:D,company:e,job_title:"🏆掘金签约作者｜人工智能方向",avatar_large:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",description:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",followee_count:b,follower_count:b,post_article_count:b,digg_article_count:b,got_digg_count:b,got_view_count:b,post_shortmsg_count:b,digg_shortmsg_count:b,isfollowed:a,favorable_author:b,power:b,study_point:b,university:{university_id:f,name:e,logo:e},major:{major_id:f,parent_id:f,name:e},student_status:b,select_event_count:b,select_online_course_count:b,identity:b,is_select_annual:a,select_annual_rank:b,annual_list_type:b,extraMap:{},is_logout:b,annual_info:[],account_amount:b,user_growth_info:{user_id:b,jpower:b,jscore:b,jpower_level:b,jscore_level:b,jscore_title:e,author_achievement_list:[],vip_level:b,vip_title:e,jscore_next_level_score:b,jscore_this_level_mini_score:b,vip_score:b},is_vip:a,become_author_days:b,collection_set_article_count:b,recommend_article_count_daily:b,article_collect_count_daily:b,user_priv_info:{administrator:b,builder:b,favorable_author:b,book_author:b,forbidden_words:b,can_tag_cnt:b,auto_recommend:b,signed_author:b,popular_author:b,can_add_video:b},juejinPower:b,jobTitle:"🏆掘金签约作者｜人工智能方向",roles:{isBookAuthor:a,isFavorableAuthor:a,isCobuilder:a,isAdmin:a},username:D,blogAddress:n,selfDescription:"公众号：吃果冻不吐果冻皮，专注于AI工程化（LLM\u002FMLOps\u002FLLMOps）落地。",beLikedCount:b,beReadCount:b,followerCount:b,followingCount:b,collectionCount:b,createdCollectionCount:b,followingCollectionCount:b,postedPostsCount:b,pinCount:b,likedArticleCount:b,likedPinCount:b,avatar:"https:\u002F\u002Fp3-passport.byteacctimg.com\u002Fimg\u002Fuser-avatar\u002F61eb73e2e7c5171e52273a81f15dd39f~300x300.image",latestLoginedInAt:c,createdAt:c,updatedAt:c,phoneNumber:e,titleDescription:e,followeesCount:b,applyEventCount:b,need_lead:b,followTopicCnt:b},viewCount:n,commentsCount:o,isEvent:n,abstract:z,latestCommentAt:c,createdAt:new Date(1694528303000),updatedAt:c,isTopicEvent:a,likedCount:10,likeCount:10,content:e,originalUrl:e,type:"post",collected:a,viewsCount:5161,username:D,viewerHasLiked:a,draftId:"7260859104951468087",collectionCount:10}],cursor:f,loading:a,skeleton:a,hasMore:a,articleId:k,actionType:{UPDATE_STATE:"view\u002Fcolumn\u002Frecommend-List\u002FUPDATE_STATE",FETCH_MORE:"view\u002Fcolumn\u002Frecommend-List\u002FFETCH_MORE",FETCH:"view\u002Fcolumn\u002Frecommend-List\u002FFETCH",RESET:"view\u002Fcolumn\u002Frecommend-List\u002FRESET"},sort:q}},collection:{collection:{author:{}},actionType:{FETCH:"@\u002Fview\u002Fcollection\u002FFETCH",REFRESH:"@\u002Fview\u002Fcollection\u002FREFRESH",RESET:"@\u002Fview\u002Fcollection\u002FRESET"},list:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Fcollection\u002Flist\u002FUPDATE",FETCH:"@\u002Fview\u002Fcollection\u002Flist\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Fcollection\u002Flist\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Fcollection\u002Flist\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fcollection\u002Flist\u002FRESET"},id:e,sort:r}},gettingStarted:{category:{},actionType:{UPDATE_STATE:"@\u002Fview\u002FgettingStarted\u002FUPDATE_STATE",FOLLOW:"@\u002Fview\u002FgettingStarted\u002FFOLLOW",RESET:"@\u002Fview\u002FgettingStarted\u002FRESET",UPDATE_CATEGORY:"@\u002Fview\u002FgettingStarted\u002FUPDATE_CATEGORY"}},pin:{pin:{user:{},imageUrlList:[]},pinList:[],actionType:{FETCH:"@\u002Fview\u002Fpin\u002FFETCH",RESET:"@\u002Fview\u002Fpin\u002FRESET"},sidebar:{list:[],after:e,loading:a,isRecommend:a,hasNextPage:d,actionType:{UPDATE_STATE:"@\u002Fview\u002Fpin\u002Fsidebar\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fpin\u002Fsidebar\u002FFETCH_MORE",FETCH:"@\u002Fview\u002Fpin\u002Fsidebar\u002FFETCH",RESET:"@\u002Fview\u002Fpin\u002Fsidebar\u002FRESET"}},commentList:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Fpin\u002FcommentList\u002FUPDATE",FETCH:"@\u002Fview\u002Fpin\u002FcommentList\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Fpin\u002FcommentList\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Fpin\u002FcommentList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fpin\u002FcommentList\u002FRESET"},pinId:c},subCommentList:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Fpin\u002FsubCommentList\u002FUPDATE",FETCH:"@\u002Fview\u002Fpin\u002FsubCommentList\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Fpin\u002FsubCommentList\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Fpin\u002FsubCommentList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fpin\u002FsubCommentList\u002FRESET"},commentId:c}},topic:{topic:e,followedTopicList:[],actionType:{FETCH:"@\u002Fview\u002Ftopic\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Ftopic\u002FUPDATE_STATE",RESET:"@\u002Fview\u002Ftopic\u002FRESET"},allTopicList:{pageSize:G,page:b,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Ftopic\u002FallTopicList\u002FUPDATE",FETCH:"@\u002Fview\u002Ftopic\u002FallTopicList\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Ftopic\u002FallTopicList\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Ftopic\u002FallTopicList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Ftopic\u002FallTopicList\u002FRESET"},sortType:p},pinlist:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Ftopic\u002FpinList\u002FUPDATE",FETCH:"@\u002Fview\u002Ftopic\u002FpinList\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Ftopic\u002FpinList\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Ftopic\u002FpinList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Ftopic\u002FpinList\u002FRESET"},sortType:q},sidebar:{actionType:{RESET:"@\u002Fview\u002Ftopic\u002Fsidebar\u002FRESET",UPDATE_STATE:"@\u002Fview\u002Ftopic\u002Fsidebar\u002FUPDATE_STATE"},attender:{pageSize:h,page:g,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Ftopic\u002Fsidebar\u002Fattender\u002FUPDATE",FETCH:"@\u002Fview\u002Ftopic\u002Fsidebar\u002Fattender\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Ftopic\u002Fsidebar\u002Fattender\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Ftopic\u002Fsidebar\u002Fattender\u002FFETCH_MORE",RESET:"@\u002Fview\u002Ftopic\u002Fsidebar\u002Fattender\u002FRESET"},topicId:c}},followedList:{pageSize:G,page:b,total:b,pointer:c,lastPointer:c,list:[],loading:a,error:c,canPrev:d,canNext:d,linkList:[],lastFetchOnServer:a,actionType:{UPDATE:"@\u002Fview\u002Ftopic\u002FfollowedList\u002FUPDATE",FETCH:"@\u002Fview\u002Ftopic\u002FfollowedList\u002FFETCH",FORCE_FETCH:"@\u002Fview\u002Ftopic\u002FfollowedList\u002FFORCE_FETCH",FETCH_MORE:"@\u002Fview\u002Ftopic\u002FfollowedList\u002FFETCH_MORE",RESET:"@\u002Fview\u002Ftopic\u002FfollowedList\u002FRESET"},after:b}},recommendationIndex:{actionType:{FETCH_USER:"@\u002Fview\u002Frecommendation\u002FFETCH_USER",FETCH_MORE:"@\u002Fview\u002Frecommendation\u002FFETCH_MORE",RESET:"@\u002Fview\u002Frecommendation\u002FRESET",FETCH:"@\u002Fview\u002Frecommendation\u002FFETCH"},cursor:e,hasMore:e,userList:[],loading:a,skeleton:d,category:m,categoryNavList:[],serverRenderUserList:a},event:{event:{},loading:a,user:{},actionType:{FETCH:"view\u002Fevent\u002FFETCH",RESET:"view\u002Fevent\u002FRESET"}},coursesIndex:{loading:a,list:[],sort:"online",actionType:{FETCH:"view\u002Fcourses\u002FFETCH",RESET:"view\u002Fcourses\u002FRESET",FETCH_MORE:"view\u002Fcourses\u002FFETCH_MORE"}},team:{team:{},loading:d,actionType:{FETCH:"@\u002Fview\u002Fteam\u002FFETCH",RESET:"@\u002Fview\u002Fteam\u002FRESET",UPDATE:"@\u002Fview\u002Fteam\u002FUPDATE",FOLLOW:"@\u002Fview\u002Fteam\u002FFOLLOW"},detailList:{actionType:{RESET:"@\u002Fview\u002Fteam\u002FdetailList\u002FRESET"},posts:{list:[],hasMore:a,skeleton:a,loading:a,sort:r,actionType:{FETCH:"@\u002Fview\u002Fteam\u002FdetailList\u002Fposts\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fteam\u002FdetailList\u002Fposts\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fteam\u002FdetailList\u002Fposts\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fteam\u002FdetailList\u002Fposts\u002FRESET"}},pins:{list:[],hasMore:a,loading:a,skeleton:d,actionType:{FETCH:"@\u002Fview\u002Fteam\u002FdetailList\u002Fpins\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fteam\u002FdetailList\u002Fpins\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fteam\u002FdetailList\u002Fpins\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fteam\u002FdetailList\u002Fpins\u002FRESET"}},hire:{list:[],hasMore:a,cursor:f,loading:a,skeleton:d,actionType:{FETCH:"@\u002Fview\u002Fteam\u002FdetailList\u002Fhire\u002FFETCH",UPDATE_STATE:"@\u002Fview\u002Fteam\u002FdetailList\u002Fhire\u002FUPDATE_STATE",FETCH_MORE:"@\u002Fview\u002Fteam\u002FdetailList\u002Fhire\u002FFETCH_MORE",RESET:"@\u002Fview\u002Fteam\u002FdetailList\u002Fhire\u002FRESET"}}}},couponList:{list:{"0":u,"1":u,"2":u},showTooltip:a},payment:{selectedDiscount:{},bookletDetail:{},coupons:{availables:[],unavailables:[]},discountList:[]},activityVip:{selectedVipSku:{}}},component:{indexAside:{bannerList:[],userList:[],botList:[],botCursor:e,actionType:{FETCH_BANNER:"@\u002Fcomponent\u002Faside\u002FFETCH_BANNER",FETCH_USER:"@\u002Fcomponent\u002Faside\u002FFETCH_USER",CLOSE_BANNER:"@\u002Fcomponent\u002Faside\u002FCLOSE_BANNER",FETCH_BOT:"@\u002Fcomponent\u002Faside\u002FFETCH_BOT"}}},dislike:{whiteList:["1398234521548542",H,I,J,K,L,M],officialList:[H,I,"3984285868490807",J,"3562073405009031",K,"4433674252325966","53218623894222","2110693287406632","2498524693925623","430664288836334",L,M,"2832783991648407","3386151545092589"]},ore:{oreCount:b},avatarMenuInfo:{user_basic:{},user_counter:{},user_growth_info:{}},common:{theme:"light",isFollowSystem:a},env:{ua:"Mozilla\u002F5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F114.0.0.0 Safari\u002F537.36",serverEnv:"production",logId:"20240820214833054642A1C3CD6E078989"},auth:{user:c,clientId:c,token:c,qrCode:c,qrCodeStatus:c,qrCodeToken:c,userInitiated:a,loginTeaParams:n},tag:{subscribedTagList:[]},entry:{isLikeLoading:a},collection:{},comment:{},bookComment:{},repoComment:{},category:{list:[]},user:{subscribedTagList:[]},notification:{unreadCount:{user:b,system:b,total:b}},error:{location:c,errorView:c,statusCode:200,needRiskModal:a,riskAppealUrl:e},abTest:{info:{}},suspensionPanel:{needSuspension:d},pinComment:{},pin:{deleteDialogVisible:a,reportDialogVisible:a,targetPin:c,isOnFocus:a},topic:{visible:a},activity:{"2020":{},offer:{is_show:b,start_time:b},voteData:n},header:{leadStep:b,isPopupZlink:a},tcc:{tccConfig:c},adAssets:{adverts:[]},route:{name:N,path:v,hash:e,query:{},params:{id:k},fullPath:v,meta:{isAvailableDarkMode:d},from:{name:c,path:O,hash:e,query:{},params:{},fullPath:O,meta:{}}}},serverRendered:d,routePath:v,config:{API_HOST:"api.juejin.cn",CAPTCHA_HOST:"verify.snssdk.com",PLATFORM_APPID:{wechat:1277,weibo:1276,github:1045,wechatApp:1070},SCM_VERSION:"1.0.0.384",REGISTERED_ROUTES:[N,"selfPost","noCDNPost","SeoSearch"],http:{}},globalRefs:{}}}(false,0,null,true,"","0",1,20,"topic",3,"7273680143658287156",-62135596800,"recommended",void 0,2,"hot","popular","newest","following",5,{},"\u002Fpost\u002F7273680143658287156","created","3642056016410728","大模型分布式训练并行技术（五）-序列并行","近年来，随着Transformer、MOE架构的提出，使得深度学习模型轻松突破上万亿规模参数，传统的单机单卡","1693637052","7257058920920170553",3236,"吃果冻不吐果冻皮",11587,{},100,"1556564194374926","940837680722589","2780007432717400","1204720443866983","852876722177533","3227821828225517","column","\u002F"));</script><script src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/105ea51.js" defer></script><script src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/e4973f7.js" defer></script><script src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/e1944c2.js" defer></script><script src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/f33ff28.js" defer></script><script src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/8acc73a.js" defer></script><script src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/80ab6d9.js" defer></script><script src="//lf-web-assets.juejin.cn/obj/juejin-web/xitu_juejin_web/90cf368.js" defer></script>
  </body>
</html>
